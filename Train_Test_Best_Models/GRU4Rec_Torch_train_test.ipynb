{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups\n",
    "import subprocess\n",
    "import torch\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar un modelo, rastrear las emisiones de CO2 y guardar la información de entrenamiento\n",
    "def track_training_C02_emissions(command, trained_model_folder, lossFunction, dataset):\n",
    "\n",
    "    # Inicializamos el tracker\n",
    "    tracker = EmissionsTracker()\n",
    "    \n",
    "    try:\n",
    "        # Obtenemos la fecha y hora de inicio\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        #iniciamos el tracker\n",
    "        tracker.start()\n",
    "        \n",
    "        # Ejecutamos el comando de entrenamiento\n",
    "        training_process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Detenemos el tracker y obtenemos las emisiones finales\n",
    "        emissions = tracker.stop()\n",
    "\n",
    "        # Obtenemos la fecha y hora de finalización\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        # Imprimimos la salida de la ejecución\n",
    "        print(f\"Salida de STDOUT: {training_process.stdout}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Ruta del archivo JSON\n",
    "    json_file_path = os.path.join(\"..\", \"trained_models\", trained_model_folder ,\"trainingData.json\")\n",
    "    \n",
    "    # Leer el archivo JSON existente\n",
    "    existing_data = []\n",
    "    if os.path.exists(json_file_path):\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"El archivo {json_file_path} está vacío o contiene datos inválidos, se inicializará como una lista vacía.\")\n",
    "            existing_data = []\n",
    "\n",
    "    # Preparar la información del entrenamiento\n",
    "    training_info = {\n",
    "        \"training_iteration\": len(existing_data) + 1,  # Número de iteración basado en el tamaño del dataset existente\n",
    "        \"date\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"execution_time_seconds\": (end_time - start_time).total_seconds(),\n",
    "        \"CO2_emissions_kg\": emissions,\n",
    "        \"LossFunction\": lossFunction,\n",
    "        \"dataset\": dataset\n",
    "\n",
    "    }\n",
    "\n",
    "    # Agregar la nueva información del entrenamiento\n",
    "    existing_data.append(training_info)\n",
    "\n",
    "    # Escribir los datos actualizados al archivo JSON\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "    # Finalmente, retornamos las emisiones de CO2\n",
    "    return emissions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga los datasets, links disponibles en el README.\n",
    "dataset_path = \"../datasets/diginetica\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run coveo_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Especificar nombre del dataset para obtener sus mejores parámetros según experiment_setup.py, y los archivos de entrenamiento\n",
    "# y test en la carpeta datasets\n",
    "datasetParams = \"diginetica\"\n",
    "datasetTrainFile =  \"diginetica_processed_view_train_full.tsv\"\n",
    "datasetTestFile = \"diginetica_processed_view_test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[datasetParams][\"params_bprmax\"]\n",
    "params2 = setups[datasetParams][\"params_xe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file:  ../datasets/diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Test file:  ../datasets/diginetica\\diginetica_processed_view_test.tsv\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_path,datasetTrainFile)\n",
    "test_path = os.path.join(dataset_path,datasetTestFile)\n",
    "\n",
    "print(\"Training file: \", train_path)\n",
    "print(\"Test file: \", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, sep='\\t')\n",
    "num_sessions = df['SessionId'].nunique()\n",
    "num_items = df['ItemId'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de cada columna:\n",
      "SessionId    int64\n",
      "ItemId       int64\n",
      "Time         int64\n",
      "dtype: object\n",
      "Number of distinct sessions: 168876\n",
      "Number of distinct items: 40366\n",
      "tamaño del dataset\n",
      "(791354, 3)\n",
      "\n",
      "Primeras 10 filas del dataset:\n",
      "    SessionId  ItemId        Time\n",
      "0           1    9654 -1831772088\n",
      "1           1   33043 -1831674024\n",
      "2           1   32118 -1831604367\n",
      "3           1   12352 -1831518066\n",
      "4           1   35077 -1831457864\n",
      "5           1   36118 -1831360567\n",
      "6           1   81766 -1831321627\n",
      "7           1   31331 -1830816918\n",
      "8           1   32627 -1830735528\n",
      "9           2  100747 -1831809619\n",
      "10          2   35606 -1831794252\n",
      "11          2   32971 -1831665177\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los tipos de datos de cada columna\n",
    "print(\"Tipos de datos de cada columna:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"Number of distinct sessions: {num_sessions}\")\n",
    "\n",
    "print(f\"Number of distinct items: {num_items}\")\n",
    "\n",
    "\n",
    "print(\"tamaño del dataset\")\n",
    "print(df.shape)\n",
    "\n",
    "# Mostrar las primeras 10 filas del dataset\n",
    "print(\"\\nPrimeras 10 filas del dataset:\")\n",
    "print(df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_gru4rec_script(model_name, train_path, test_path, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, sample_alpha, bpreg, n_epochs, n_sample, m):\n",
    "    s_train_full = f\" python ../Torch-GRU4Rec/main.py --save_path {model_path}/{model_name} --train_path {train_path} --loss {'nll' if loss =='cross-entropy' else loss} --optimizer {optim} --n_epochs {n_epochs} --embedding_size {layers} --hidden_size {layers} --n_layers {1} --final_act {'softmaxlogit' if final_act=='softmax' else final_act} --batch_size {batch_size} --dropout_p_embed {dropout_p_embed} --dropout_p_hidden {dropout_p_hidden} --lr {learning_rate} --n_sample {n_sample} --sample_alpha {sample_alpha} --bpreg {bpreg}\"\n",
    "    s_test_full = f\" python ../Torch-GRU4Rec/main.py --train_path {train_path} --test_path {test_path} --model_path {model_path}/{model_name}/model_0000{n_epochs-1}.pt --test  --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_sample = params[\"n_sample\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = params2[\"loss\"]\n",
    "optim2 = params2[\"optim\"]\n",
    "const_emb2 = params2[\"constrained_embedding\"]\n",
    "embed2 = params2[\"embedding\"]\n",
    "final_act2 = params2[\"final_act\"]\n",
    "layers2 = params2[\"layers\"]\n",
    "batch_size2 = params2[\"batch_size\"]\n",
    "dropout_p_embed2 = params2[\"dropout_p_embed\"]\n",
    "dropout_p_hidden2 = params2[\"dropout_p_hidden\"]\n",
    "learning_rate2 = params2[\"learning_rate\"]\n",
    "momentum2 = params2[\"momentum\"]\n",
    "sample_alpha2 = params2[\"sample_alpha\"]\n",
    "bpreg2 = params2[\"bpreg\"]\n",
    "logq2 = params2[\"logq\"]\n",
    "hidden_act2 = params2[\"hidden_act\"]\n",
    "n_sample2 = params2[\"n_sample\"]\n",
    "n_epochs2 = 5\n",
    "m2 = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los scrip necesarios para entrenar el modelo con BPR-MAX\n",
    "train_script_oob_bpr, test_script_oob_bpr = create_torch_gru4rec_script(model_name='torch_gru4rec_oob_bprmax', train_path=train_path, test_path=test_path, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, sample_alpha=sample_alpha, bpreg=bpreg, n_epochs=n_epochs, n_sample=n_sample, m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los scrip necesarios para entrenar el modelo con Cross-Entropy\n",
    "train_script_oob_xl, test_script_oob_xl = create_torch_gru4rec_script(model_name='torch_gru4rec_oob_bprmax', train_path=train_path, test_path=test_path, model_path=model_path, loss=loss2, optim=optim2, final_act=final_act2, layers=layers2, batch_size=batch_size2, dropout_p_embed=dropout_p_embed2, dropout_p_hidden=dropout_p_hidden2, learning_rate=learning_rate2, sample_alpha=sample_alpha2, bpreg=bpreg2, n_epochs=n_epochs2, n_sample=n_sample2, m=m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " python ../Torch-GRU4Rec/main.py --save_path ../trained_models/torch_gru4rec_oob_bprmax --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --loss bpr-max --optimizer adagrad --n_epochs 5 --embedding_size 512 --hidden_size 512 --n_layers 1 --final_act elu-1 --batch_size 128 --dropout_p_embed 0.5 --dropout_p_hidden 0.3 --lr 0.05 --n_sample 2048 --sample_alpha 0.3 --bpreg 0.9\n",
      " python ../Torch-GRU4Rec/main.py --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --test_path ../datasets/diginetica\\diginetica_processed_view_test.tsv --model_path ../trained_models/torch_gru4rec_oob_bprmax/model_00004.pt --test  --m 1 5 10 20\n",
      "\n",
      "\n",
      " python ../Torch-GRU4Rec/main.py --save_path ../trained_models/torch_gru4rec_oob_bprmax --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --loss nll --optimizer adagrad --n_epochs 5 --embedding_size 192 --hidden_size 192 --n_layers 1 --final_act softmaxlogit --batch_size 128 --dropout_p_embed 0.45 --dropout_p_hidden 0.15 --lr 0.1 --n_sample 2048 --sample_alpha 0.0 --bpreg 0.0\n",
      " python ../Torch-GRU4Rec/main.py --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --test_path ../datasets/diginetica\\diginetica_processed_view_test.tsv --model_path ../trained_models/torch_gru4rec_oob_bprmax/model_00004.pt --test  --m 1 5 10 20\n"
     ]
    }
   ],
   "source": [
    "print(train_script_oob_bpr)\n",
    "print(test_script_oob_bpr)\n",
    "print(\"\\n\")\n",
    "print(train_script_oob_xl)\n",
    "print(test_script_oob_xl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Nos aseguramos de que tenemos funcionando la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 22:57:55] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 22:57:55] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 22:57:55] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 22:57:55] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 22:57:55] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 22:57:55] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 22:57:56] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 22:57:56] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 22:57:56] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 22:57:56]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 22:57:56]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 22:57:56]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 22:57:56]   Available RAM : 29.701 GB\n",
      "[codecarbon INFO @ 22:57:56]   CPU count: 24\n",
      "[codecarbon INFO @ 22:57:56]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 22:57:56]   GPU count: 1\n",
      "[codecarbon INFO @ 22:57:56]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 22:58:12] Energy consumed for RAM : 0.000046 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:58:12] Energy consumed for all GPUs : 0.000196 kWh. Total GPU Power : 46.92856184778401 W\n",
      "[codecarbon INFO @ 22:58:12] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:58:12] 0.000419 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:58:27] Energy consumed for RAM : 0.000093 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:58:27] Energy consumed for all GPUs : 0.000454 kWh. Total GPU Power : 62.01764871300995 W\n",
      "[codecarbon INFO @ 22:58:27] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:58:27] 0.000901 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:58:42] Energy consumed for RAM : 0.000139 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:58:42] Energy consumed for all GPUs : 0.000715 kWh. Total GPU Power : 62.667738110837426 W\n",
      "[codecarbon INFO @ 22:58:42] Energy consumed for all CPUs : 0.000531 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:58:42] 0.001386 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:58:57] Energy consumed for RAM : 0.000186 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:58:57] Energy consumed for all GPUs : 0.000978 kWh. Total GPU Power : 62.99569478993902 W\n",
      "[codecarbon INFO @ 22:58:57] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:58:57] 0.001872 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:59:12] Energy consumed for RAM : 0.000232 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:59:12] Energy consumed for all GPUs : 0.001249 kWh. Total GPU Power : 65.10317824486997 W\n",
      "[codecarbon INFO @ 22:59:12] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:59:12] 0.002367 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:59:27] Energy consumed for RAM : 0.000278 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:59:27] Energy consumed for all GPUs : 0.001494 kWh. Total GPU Power : 58.616720445521736 W\n",
      "[codecarbon INFO @ 22:59:27] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:59:27] 0.002835 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:59:42] Energy consumed for RAM : 0.000325 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:59:42] Energy consumed for all GPUs : 0.001760 kWh. Total GPU Power : 63.970482127804345 W\n",
      "[codecarbon INFO @ 22:59:42] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:59:42] 0.003325 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:59:57] Energy consumed for RAM : 0.000371 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 22:59:57] Energy consumed for all GPUs : 0.002031 kWh. Total GPU Power : 64.90852528259501 W\n",
      "[codecarbon INFO @ 22:59:57] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:59:57] 0.003819 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:00:12] Energy consumed for RAM : 0.000418 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:00:12] Energy consumed for all GPUs : 0.002303 kWh. Total GPU Power : 65.30459780478049 W\n",
      "[codecarbon INFO @ 23:00:12] Energy consumed for all CPUs : 0.001595 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:00:12] 0.004315 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:00:27] Energy consumed for RAM : 0.000464 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:00:27] Energy consumed for all GPUs : 0.002573 kWh. Total GPU Power : 64.74867888577225 W\n",
      "[codecarbon INFO @ 23:00:27] Energy consumed for all CPUs : 0.001772 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:00:27] 0.004808 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:00:42] Energy consumed for RAM : 0.000510 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:00:42] Energy consumed for all GPUs : 0.002821 kWh. Total GPU Power : 59.58990608725117 W\n",
      "[codecarbon INFO @ 23:00:42] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:00:42] 0.005280 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:00:57] Energy consumed for RAM : 0.000557 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:00:57] Energy consumed for all GPUs : 0.003093 kWh. Total GPU Power : 65.1187836436718 W\n",
      "[codecarbon INFO @ 23:00:57] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:00:57] 0.005776 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:01:12] Energy consumed for RAM : 0.000603 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:01:12] Energy consumed for all GPUs : 0.003362 kWh. Total GPU Power : 64.60439882505636 W\n",
      "[codecarbon INFO @ 23:01:12] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:01:12] 0.006269 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:01:27] Energy consumed for RAM : 0.000650 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:01:27] Energy consumed for all GPUs : 0.003632 kWh. Total GPU Power : 64.71365918439005 W\n",
      "[codecarbon INFO @ 23:01:27] Energy consumed for all CPUs : 0.002481 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:01:27] 0.006762 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:01:42] Energy consumed for RAM : 0.000696 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:01:42] Energy consumed for all GPUs : 0.003903 kWh. Total GPU Power : 64.9691512703753 W\n",
      "[codecarbon INFO @ 23:01:42] Energy consumed for all CPUs : 0.002658 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:01:42] 0.007256 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:01:57] Energy consumed for RAM : 0.000742 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:01:57] Energy consumed for all GPUs : 0.004151 kWh. Total GPU Power : 59.67778931746265 W\n",
      "[codecarbon INFO @ 23:01:57] Energy consumed for all CPUs : 0.002835 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:01:57] 0.007728 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:02:12] Energy consumed for RAM : 0.000789 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:02:12] Energy consumed for all GPUs : 0.004422 kWh. Total GPU Power : 65.04730180899257 W\n",
      "[codecarbon INFO @ 23:02:12] Energy consumed for all CPUs : 0.003012 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:02:12] 0.008223 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:02:27] Energy consumed for RAM : 0.000835 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:02:27] Energy consumed for all GPUs : 0.004693 kWh. Total GPU Power : 64.84044306873338 W\n",
      "[codecarbon INFO @ 23:02:27] Energy consumed for all CPUs : 0.003189 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:02:27] 0.008717 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:02:42] Energy consumed for RAM : 0.000881 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:02:42] Energy consumed for all GPUs : 0.004966 kWh. Total GPU Power : 65.49871735653376 W\n",
      "[codecarbon INFO @ 23:02:42] Energy consumed for all CPUs : 0.003366 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:02:42] 0.009213 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:02:57] Energy consumed for RAM : 0.000928 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:02:57] Energy consumed for all GPUs : 0.005240 kWh. Total GPU Power : 65.9308351716288 W\n",
      "[codecarbon INFO @ 23:02:57] Energy consumed for all CPUs : 0.003543 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:02:57] 0.009712 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:03:12] Energy consumed for RAM : 0.000974 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:03:12] Energy consumed for all GPUs : 0.005488 kWh. Total GPU Power : 59.46002289540894 W\n",
      "[codecarbon INFO @ 23:03:12] Energy consumed for all CPUs : 0.003721 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:03:12] 0.010183 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:03:27] Energy consumed for RAM : 0.001021 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:03:27] Energy consumed for all GPUs : 0.005759 kWh. Total GPU Power : 64.97853954211106 W\n",
      "[codecarbon INFO @ 23:03:27] Energy consumed for all CPUs : 0.003898 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:03:27] 0.010677 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:03:42] Energy consumed for RAM : 0.001067 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:03:42] Energy consumed for all GPUs : 0.006032 kWh. Total GPU Power : 65.50615444932363 W\n",
      "[codecarbon INFO @ 23:03:42] Energy consumed for all CPUs : 0.004075 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:03:42] 0.011174 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:03:57] Energy consumed for RAM : 0.001113 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:03:57] Energy consumed for all GPUs : 0.006304 kWh. Total GPU Power : 65.35827393772257 W\n",
      "[codecarbon INFO @ 23:03:57] Energy consumed for all CPUs : 0.004252 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:03:57] 0.011670 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:04:12] Energy consumed for RAM : 0.001160 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:04:12] Energy consumed for all GPUs : 0.006577 kWh. Total GPU Power : 65.52794192855593 W\n",
      "[codecarbon INFO @ 23:04:12] Energy consumed for all CPUs : 0.004429 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:04:12] 0.012166 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-42 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 596: character maps to <undefined>\n",
      "[codecarbon INFO @ 23:04:14] Energy consumed for RAM : 0.001165 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 23:04:14] Energy consumed for all GPUs : 0.006595 kWh. Total GPU Power : 39.67619758686242 W\n",
      "[codecarbon INFO @ 23:04:14] Energy consumed for all CPUs : 0.004448 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 23:04:14] 0.012208 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT:                   Args                                             Values\n",
      "0            save_path         ../trained_models/torch_gru4rec_oob_bprmax\n",
      "1           train_path  ../datasets/diginetica\\diginetica_processed_vi...\n",
      "2           valid_path                                                   \n",
      "3            test_path                                                   \n",
      "4                 test                                              False\n",
      "5                    m                                               [20]\n",
      "6           model_path                                                   \n",
      "7             n_epochs                                                  5\n",
      "8                 loss                                            bpr-max\n",
      "9            optimizer                                            adagrad\n",
      "10                  lr                                               0.05\n",
      "11      embedding_size                                                512\n",
      "12         hidden_size                                                512\n",
      "13            n_layers                                                  1\n",
      "14          batch_size                                                128\n",
      "15            n_sample                                               2048\n",
      "16      valid_n_sample                                                  0\n",
      "17     dropout_p_embed                                                0.5\n",
      "18    dropout_p_hidden                                                0.3\n",
      "19           final_act                                              elu-1\n",
      "20               bpreg                                                0.9\n",
      "21        sample_alpha                                                0.3\n",
      "22      init_as_normal                                              False\n",
      "23               sigma                                                0.0\n",
      "24         session_key                                          SessionId\n",
      "25            item_key                                             ItemId\n",
      "26            time_key                                               Time\n",
      "27                 sep                                                 \\t\n",
      "28            use_cuda                                               True\n",
      "29        weight_decay                                                0.0\n",
      "30            momentum                                                0.0\n",
      "31           time_sort                                               True\n",
      "32  train_random_order                                              False\n",
      "Loading data from ../datasets/diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Result Folder:../trained_models/torch_gru4rec_oob_bprmax\n",
      "#### START TRAINING....\n",
      "Start Epoch # 0\n",
      "epoch:0 loss: 0.587173 73.46 s 8473.46 e/s 66.32 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00000.pt\n",
      "Start Epoch # 1\n",
      "epoch:1 loss: 0.369323 74.16 s 8394.00 e/s 65.70 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00001.pt\n",
      "Start Epoch # 2\n",
      "epoch:2 loss: 0.316252 74.02 s 8409.25 e/s 65.82 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00002.pt\n",
      "Start Epoch # 3\n",
      "epoch:3 loss: 0.292275 74.17 s 8392.63 e/s 65.69 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00003.pt\n",
      "Start Epoch # 4\n",
      "epoch:4 loss: 0.278065 74.00 s 8412.28 e/s 65.84 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.0040605632061905105 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    emissions = track_training_C02_emissions(train_script_oob_bpr, \"torch_gru4rec_oob_bprmax\", \"BPR-Max\", \"Diginetica\")\n",
    "    # Imprimimos las emisiones de carbono con estilo\n",
    "    if emissions is not None:\n",
    "        display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "    else:\n",
    "        display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-37 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 70: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT:                   Args                                             Values\n",
      "0            save_path                                                   \n",
      "1           train_path  ../datasets/diginetica\\diginetica_processed_vi...\n",
      "2           valid_path                                                   \n",
      "3            test_path  ../datasets/diginetica\\diginetica_processed_vi...\n",
      "4                 test                                               True\n",
      "5                    m                                     [1, 5, 10, 20]\n",
      "6           model_path  ../trained_models/torch_gru4rec_oob_bprmax/mod...\n",
      "7             n_epochs                                                  5\n",
      "8                 loss                                                nll\n",
      "9            optimizer                                            adagrad\n",
      "10                  lr                                               None\n",
      "11      embedding_size                                                 -1\n",
      "12         hidden_size                                               None\n",
      "13            n_layers                                               None\n",
      "14          batch_size                                               None\n",
      "15            n_sample                                               2048\n",
      "16      valid_n_sample                                                  0\n",
      "17     dropout_p_embed                                                0.0\n",
      "18    dropout_p_hidden                                                0.0\n",
      "19           final_act                                       softmaxlogit\n",
      "20               bpreg                                                1.0\n",
      "21        sample_alpha                                                1.0\n",
      "22      init_as_normal                                              False\n",
      "23               sigma                                                0.0\n",
      "24         session_key                                          SessionId\n",
      "25            item_key                                             ItemId\n",
      "26            time_key                                               Time\n",
      "27                 sep                                                 \\t\n",
      "28            use_cuda                                               True\n",
      "29        weight_decay                                                0.0\n",
      "30            momentum                                                0.0\n",
      "31           time_sort                                               True\n",
      "32  train_random_order                                              False\n",
      "Loading data from ../datasets/diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Loading data from ../datasets/diginetica\\diginetica_processed_view_test.tsv\n",
      "Test results\n",
      "recall\tmrr\t@[1, 5, 10, 20]\n",
      "Recall@1: 0.064306802 MRR@1: 0.064306803\n",
      "Recall@5: 0.20924531 MRR@5: 0.1140554\n",
      "Recall@10: 0.3146528 MRR@10: 0.12801321\n",
      "Recall@20: 0.44572782 MRR@20: 0.13701971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_process = subprocess.run(test_script_oob_bpr, shell=True, capture_output=True, text=True)\n",
    "print(f\"Salida de STDOUT: {test_process.stdout}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
