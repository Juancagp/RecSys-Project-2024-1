{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset, the links can be fund in the README\n",
    "dataset_path = \"../datasets/coveo_ecommerce\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566074 274797 11365\n",
      "1464757 173480 11344\n",
      "1463706 173480 10869\n",
      "1463649 173423 10869\n",
      "1463645 173423 10868\n",
      "1463645 173423 10868\n",
      "1463645 173423 10868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Dataset  NumEvents  NumSessions  \\\n",
      "0      coveo_ecommerce\\coveo_processed_view_full.tsv    1463645       173423   \n",
      "1      coveo_ecommerce\\coveo_processed_view_test.tsv      52501         7748   \n",
      "2  coveo_ecommerce\\coveo_processed_view_train_ful...    1411113       165673   \n",
      "3  coveo_ecommerce\\coveo_processed_view_train_tr.tsv    1368003       159766   \n",
      "4  coveo_ecommerce\\coveo_processed_view_train_val...      43032         5905   \n",
      "\n",
      "   NumItems    NumDays                   StartTime  \\\n",
      "0     10868  17.999833  2018-12-08 00:00:11.994000   \n",
      "1      8230   0.998696  2018-12-25 00:01:50.223000   \n",
      "2     10868  16.999566  2018-12-08 00:00:11.994000   \n",
      "3     10868  15.999713  2018-12-08 00:00:11.994000   \n",
      "4      8014   0.997503  2018-12-24 00:03:10.240000   \n",
      "\n",
      "                      EndTime  AvgItemViews  MinSessionLength  \\\n",
      "0  2018-12-25 23:59:57.577000    134.674733                 2   \n",
      "1  2018-12-25 23:59:57.577000      6.379222                 2   \n",
      "2  2018-12-24 23:59:34.483000    129.841093                 2   \n",
      "3  2018-12-23 23:59:47.187000    125.874402                 2   \n",
      "4  2018-12-24 23:59:34.483000      5.369603                 2   \n",
      "\n",
      "   MaxSessionLength  AvgSessionLength  MinSessionTime (sec)  \\\n",
      "0               454          8.439740                 0.001   \n",
      "1               146          6.776071                 0.001   \n",
      "2               454          8.517459                 0.001   \n",
      "3               454          8.562541                 0.001   \n",
      "4               134          7.287384                 0.004   \n",
      "\n",
      "   MaxSessionTime (sec)  \n",
      "0             59683.003  \n",
      "1             12440.338  \n",
      "2             59683.003  \n",
      "3             59683.003  \n",
      "4             11941.152  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n"
     ]
    }
   ],
   "source": [
    "%run ../Preprocess/coveo_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[\"coveo\"][\"params_bprmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,\"coveo_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,\"coveo_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru4rec_pytorch_script(model_name, train_folder, train_data, test_data, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, n_epochs, m, eval_hidden_reset, use_correct_loss, use_correct_mask_reset):\n",
    "    checkpoint_dir = f\"{model_path}\\\\{model_name}\"\n",
    "    s_train_full = (\n",
    "        f\"python ..\\\\GRU4REC-pytorch\\\\main.py --data_folder {train_folder} \"\n",
    "        f\"--train_data {train_data} --valid_data {test_data} --checkpoint_dir {checkpoint_dir} \"\n",
    "        f\"--num_layers 1 --embedding_dim {layers} --hidden_size {layers} \"\n",
    "        f\"--loss_type {'BPR-max' if loss == 'bpr-max' else 'CrossEntropy'} --final_act {final_act} \"\n",
    "        f\"--n_epochs {n_epochs} --batch_size {batch_size} --dropout_input {dropout_p_embed} \"\n",
    "        f\"--dropout_hidden {dropout_p_hidden} --lr {learning_rate} --momentum 0.0 \"\n",
    "        f\"--optimizer_type {'Adagrad' if optim == 'adagrad' else ''}\"\n",
    "        f\"{' --eval_hidden_reset' if eval_hidden_reset else ''}\"\n",
    "        f\"{' --use_correct_loss' if use_correct_loss else ''}\"\n",
    "        f\"{' --use_correct_mask_reset' if use_correct_mask_reset else ''}\"\n",
    "    )\n",
    "    s_test_full = s_train_full + f\" --is_eval --load_model {checkpoint_dir}\\\\model_0000{n_epochs-1}.pt --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, train_data = '/'.join(train_path.split('/')[:-1]), train_path.split('/')[-1]\n",
    "test_folder, test_data = '/'.join(test_path.split('/')[:-1]), test_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob, test_script_oob = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_oob_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=False, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=0 python3 ../GRU4REC-pytorch/main.py --data_folder ../datasets/coveo_ecommerce --train_data coveo_processed_view_train_full.tsv --valid_data coveo_processed_view_test.tsv --checkpoint_dir ../trained_models/gru4rec_pytorch_oob_bprmax --num_layers 1 --embedding_dim 512 --hidden_size 512 --loss_type BPR-max --final_act elu-1 --n_epochs 5 --batch_size 144 --dropout_input 0.0 --dropout_hidden 0.0 --lr 0.05 --momentum 0.0 --optimizer_type Adagrad\n",
      "CUDA_VISIBLE_DEVICES=0 python3 ../GRU4REC-pytorch/main.py --data_folder ../datasets/coveo_ecommerce --train_data coveo_processed_view_train_full.tsv --valid_data coveo_processed_view_test.tsv --checkpoint_dir ../trained_models/gru4rec_pytorch_oob_bprmax --num_layers 1 --embedding_dim 512 --hidden_size 512 --loss_type BPR-max --final_act elu-1 --n_epochs 5 --batch_size 144 --dropout_input 0.0 --dropout_hidden 0.0 --lr 0.05 --momentum 0.0 --optimizer_type Adagrad --is_eval --load_model ../trained_models/gru4rec_pytorch_oob_bprmax/model_00004.pt --m 1 5 10 20\n"
     ]
    }
   ],
   "source": [
    "print(train_script_oob)\n",
    "print(test_script_oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../trained_models/gru4rec_pytorch_oob_bprmax\"\n",
    "eval_hidden_reset=False\n",
    "use_correct_loss=False\n",
    "use_correct_mask_reset=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT (Entrenamiento):\n",
      "\n",
      "Salida de STDERR (Entrenamiento):\n",
      "Traceback (most recent call last):\n",
      "  File \"../GRU4REC-pytorch/main.py\", line 3, in <module>\n",
      "    import lib\n",
      "  File \"/home/juancagp/RecSysProject/RecSys-Project-2024-1/GRU4REC-pytorch/lib/__init__.py\", line 1, in <module>\n",
      "    from .dataset import Dataset, DataLoader\n",
      "  File \"/home/juancagp/RecSysProject/RecSys-Project-2024-1/GRU4REC-pytorch/lib/dataset.py\", line 3, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "\n",
      "Salida de STDOUT (Evaluación):\n",
      "\n",
      "Salida de STDERR (Evaluación):\n",
      "Traceback (most recent call last):\n",
      "  File \"../GRU4REC-pytorch/main.py\", line 3, in <module>\n",
      "    import lib\n",
      "  File \"/home/juancagp/RecSysProject/RecSys-Project-2024-1/GRU4REC-pytorch/lib/__init__.py\", line 1, in <module>\n",
      "    from .dataset import Dataset, DataLoader\n",
      "  File \"/home/juancagp/RecSysProject/RecSys-Project-2024-1/GRU4REC-pytorch/lib/dataset.py\", line 3, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Comando de entrenamiento\n",
    "process_train = subprocess.Popen(train_script_oob, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_train, stderr_train = process_train.communicate()\n",
    "\n",
    "print(\"Salida de STDOUT (Entrenamiento):\")\n",
    "print(stdout_train.decode())\n",
    "print(\"Salida de STDERR (Entrenamiento):\")\n",
    "print(stderr_train.decode())\n",
    "\n",
    "# Comando de evaluación\n",
    "process_test = subprocess.Popen(test_script_oob, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_test, stderr_test = process_test.communicate()\n",
    "\n",
    "print(\"Salida de STDOUT (Evaluación):\")\n",
    "print(stdout_test.decode())\n",
    "print(\"Salida de STDERR (Evaluación):\")\n",
    "print(stderr_test.decode())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: python: not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(train_script_oob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_oob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test inference fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_inffix, test_script_inffix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_inffix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(train_script_inffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_inffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix, test_script_majorfix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_majorfix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(train_script_majorfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_majorfix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
