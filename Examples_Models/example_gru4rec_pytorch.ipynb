{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups\n",
    "from model_tracker import track_training_C02_emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"diginetica\"   # coveo, diginetica, rees46, retailrocket, yoochoose\n",
    "loss_function = \"xe\"   # bprmax, xe\n",
    "\n",
    "dataset_path = f\"../datasets/{dataset}\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Preprocess/coveo_ecommerce_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[dataset][f\"params_{loss_function}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,f\"{dataset}_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,f\"{dataset}_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru4rec_pytorch_script(model_name, train_folder, train_data, test_data, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, n_epochs, m, eval_hidden_reset, use_correct_loss, use_correct_mask_reset):\n",
    "    checkpoint_dir = f\"{model_path}\\\\{model_name}\"\n",
    "    s_train_full = (\n",
    "        f\"python ..\\\\GRU4REC-pytorch\\\\main.py --data_folder {train_folder} \"\n",
    "        f\"--train_data {train_data} --valid_data {test_data} --checkpoint_dir {checkpoint_dir} \"\n",
    "        f\"--num_layers 1 --embedding_dim {layers} --hidden_size {layers} \"\n",
    "        f\"--loss_type {'BPR-max' if loss == 'bpr-max' else 'CrossEntropy'} --final_act {final_act} \"\n",
    "        f\"--n_epochs {n_epochs} --batch_size {batch_size} --dropout_input {dropout_p_embed} \"\n",
    "        f\"--dropout_hidden {dropout_p_hidden} --lr {learning_rate} --momentum 0.0 \"\n",
    "        f\"--optimizer_type {'Adagrad' if optim == 'adagrad' else ''}\"\n",
    "        f\"{' --eval_hidden_reset' if eval_hidden_reset else ''}\"\n",
    "        f\"{' --use_correct_loss' if use_correct_loss else ''}\"\n",
    "        f\"{' --use_correct_mask_reset' if use_correct_mask_reset else ''}\"\n",
    "    )\n",
    "    s_test_full = s_train_full + f\" --is_eval --load_model {checkpoint_dir}\\\\model_0000{n_epochs-1}.pt --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training folder:  ../datasets\n",
      "Train data:  diginetica\\diginetica_processed_view_train_full.tsv\n"
     ]
    }
   ],
   "source": [
    "train_folder, train_data = '/'.join(train_path.split('/')[:-1]), train_path.split('/')[-1]\n",
    "test_folder, test_data = '/'.join(test_path.split('/')[:-1]), test_path.split('/')[-1]\n",
    "\n",
    "print(\"Training folder: \", train_folder)\n",
    "print(\"Train data: \", train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test (major fix model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix, test_script_majorfix = create_gru4rec_pytorch_script(model_name=f'gru4rec_pytorch_{loss_function}', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 13:17:07] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 13:17:07] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 13:17:07] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 13:17:07] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 13:17:07] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 13:17:07] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 13:17:08] We saw that you have a 13th Gen Intel(R) Core(TM) i9-13900HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 13:17:08] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "[codecarbon INFO @ 13:17:08] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 13:17:08]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 13:17:08]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 13:17:08]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 13:17:08]   Available RAM : 31.746 GB\n",
      "[codecarbon INFO @ 13:17:08]   CPU count: 32\n",
      "[codecarbon INFO @ 13:17:08]   CPU model: 13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "[codecarbon INFO @ 13:17:08]   GPU count: 1\n",
      "[codecarbon INFO @ 13:17:08]   GPU model: 1 x NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "[codecarbon INFO @ 13:17:26] Energy consumed for RAM : 0.000050 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:17:26] Energy consumed for all GPUs : 0.000273 kWh. Total GPU Power : 65.52532174714167 W\n",
      "[codecarbon INFO @ 13:17:26] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:17:26] 0.000500 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:17:41] Energy consumed for RAM : 0.000099 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:17:41] Energy consumed for all GPUs : 0.000604 kWh. Total GPU Power : 79.43310842336554 W\n",
      "[codecarbon INFO @ 13:17:41] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:17:41] 0.001058 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:17:56] Energy consumed for RAM : 0.000149 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:17:56] Energy consumed for all GPUs : 0.000936 kWh. Total GPU Power : 79.61621302659273 W\n",
      "[codecarbon INFO @ 13:17:56] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:17:56] 0.001616 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:18:11] Energy consumed for RAM : 0.000198 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:18:11] Energy consumed for all GPUs : 0.001268 kWh. Total GPU Power : 79.65655021444113 W\n",
      "[codecarbon INFO @ 13:18:11] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:18:11] 0.002175 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:18:26] Energy consumed for RAM : 0.000248 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:18:26] Energy consumed for all GPUs : 0.001599 kWh. Total GPU Power : 79.47601125236098 W\n",
      "[codecarbon INFO @ 13:18:26] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:18:26] 0.002733 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:18:41] Energy consumed for RAM : 0.000298 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:18:41] Energy consumed for all GPUs : 0.001935 kWh. Total GPU Power : 80.49634076640535 W\n",
      "[codecarbon INFO @ 13:18:41] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:18:41] 0.003295 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-39 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\EVILAB\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 455: character maps to <undefined>\n",
      "[codecarbon INFO @ 13:18:42] Energy consumed for RAM : 0.000301 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 13:18:42] Energy consumed for all GPUs : 0.001950 kWh. Total GPU Power : 58.34066622717612 W\n",
      "[codecarbon INFO @ 13:18:42] Energy consumed for all CPUs : 0.001074 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 13:18:42] 0.003326 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT:                       Args                                             Values\n",
      "0              hidden_size                                                192\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                128\n",
      "3            dropout_input                                               0.45\n",
      "4           dropout_hidden                                               0.15\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                            softmax\n",
      "9                       lr                                                0.1\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                192\n",
      "16               loss_type                                       CrossEntropy\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  diginetica\\diginetica_processed_view_train_ful...\n",
      "22              valid_data      diginetica\\diginetica_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir               ../trained_models\\gru4rec_pytorch_xe\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                               True\n",
      "28  use_correct_mask_reset                                               True\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\diginetica\\diginetica_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 4.179430 17.60 s 35360.28 e/s 276.25 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_xe\\model_00000.pt\n",
      "epoch:1 loss: 2.685091 17.68 s 35185.43 e/s 274.89 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_xe\\model_00001.pt\n",
      "epoch:2 loss: 2.153567 17.22 s 36137.15 e/s 282.32 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_xe\\model_00002.pt\n",
      "epoch:3 loss: 1.873409 17.02 s 36564.51 e/s 285.66 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_xe\\model_00003.pt\n",
      "epoch:4 loss: 1.696359 17.03 s 36526.27 e/s 285.36 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_xe\\model_00004.pt\n",
      "\n",
      "CO2_emissions_kg: 0.0011061849842481002\n",
      "El archivo ..\\trained_models\\gru4rec_pytorch_xe\\diginetica\\trainingData.json está vacío o contiene datos inválidos, se inicializará como una lista vacía.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0011061849842481002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_training_C02_emissions(train_script_majorfix, f\"gru4rec_pytorch_{loss_function}\", dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ..\\GRU4REC-pytorch\\main.py --data_folder ../datasets --train_data diginetica\\diginetica_processed_view_train_full.tsv --valid_data diginetica\\diginetica_processed_view_test.tsv --checkpoint_dir ../trained_models\\gru4rec_pytorch_xe --num_layers 1 --embedding_dim 192 --hidden_size 192 --loss_type CrossEntropy --final_act softmax --n_epochs 5 --batch_size 128 --dropout_input 0.45 --dropout_hidden 0.15 --lr 0.1 --momentum 0.0 --optimizer_type Adagrad --eval_hidden_reset --use_correct_loss --use_correct_mask_reset --is_eval --load_model ../trained_models\\gru4rec_pytorch_xe\\model_00004.pt --m 1 5 10 20\n"
     ]
    }
   ],
   "source": [
    "print(test_script_majorfix)\n",
    "# os.system(test_script_majorfix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
