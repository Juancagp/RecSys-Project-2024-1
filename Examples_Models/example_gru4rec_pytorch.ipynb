{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset, the links can be fund in the README\n",
    "dataset_path = \"../datasets/retailrocket\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Preprocess/coveo_ecommerce_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[\"retailrocket\"][\"params_bprmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,\"retailrocket_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,\"retailrocket_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru4rec_pytorch_script(model_name, train_folder, train_data, test_data, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, n_epochs, m, eval_hidden_reset, use_correct_loss, use_correct_mask_reset):\n",
    "    checkpoint_dir = f\"{model_path}\\\\{model_name}\"\n",
    "    s_train_full = (\n",
    "        f\"python ..\\\\GRU4REC-pytorch\\\\main.py --data_folder {train_folder} \"\n",
    "        f\"--train_data {train_data} --valid_data {test_data} --checkpoint_dir {checkpoint_dir} \"\n",
    "        f\"--num_layers 1 --embedding_dim {layers} --hidden_size {layers} \"\n",
    "        f\"--loss_type {'BPR-max' if loss == 'bpr-max' else 'CrossEntropy'} --final_act {final_act} \"\n",
    "        f\"--n_epochs {n_epochs} --batch_size {batch_size} --dropout_input {dropout_p_embed} \"\n",
    "        f\"--dropout_hidden {dropout_p_hidden} --lr {learning_rate} --momentum 0.0 \"\n",
    "        f\"--optimizer_type {'Adagrad' if optim == 'adagrad' else ''}\"\n",
    "        f\"{' --eval_hidden_reset' if eval_hidden_reset else ''}\"\n",
    "        f\"{' --use_correct_loss' if use_correct_loss else ''}\"\n",
    "        f\"{' --use_correct_mask_reset' if use_correct_mask_reset else ''}\"\n",
    "    )\n",
    "    s_test_full = s_train_full + f\" --is_eval --load_model {checkpoint_dir}\\\\model_0000{n_epochs-1}.pt --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, train_data = '/'.join(train_path.split('/')[:-1]), train_path.split('/')[-1]\n",
    "test_folder, test_data = '/'.join(test_path.split('/')[:-1]), test_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob, test_script_oob = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_oob_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=False, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../trained_models/gru4rec_pytorch_oob_bprmax\"\n",
    "eval_hidden_reset=False\n",
    "use_correct_loss=False\n",
    "use_correct_mask_reset=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Comando de entrenamiento\n",
    "process_train = subprocess.Popen(train_script_oob, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_train, stderr_train = process_train.communicate()\n",
    "\n",
    "print(\"Salida de STDOUT (Entrenamiento):\")\n",
    "print(stdout_train.decode())\n",
    "print(\"Salida de STDERR (Entrenamiento):\")\n",
    "print(stderr_train.decode())\n",
    "\n",
    "# Comando de evaluación\n",
    "process_test = subprocess.Popen(test_script_oob, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_test, stderr_test = process_test.communicate()\n",
    "\n",
    "print(\"Salida de STDOUT (Evaluación):\")\n",
    "print(stdout_test.decode())\n",
    "print(\"Salida de STDERR (Evaluación):\")\n",
    "print(stderr_test.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 21:19:14] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 21:19:14] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:19:14] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:19:14] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 21:19:15] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:19:15] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 21:19:17] We saw that you have a 13th Gen Intel(R) Core(TM) i9-13900HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 21:19:17] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "[codecarbon WARNING @ 21:19:17] Failed to retrieve gpu information\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 238, in get_gpu_details\n",
      "    devices_info.append(gpu_device.get_gpu_details())\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 75, in get_gpu_details\n",
      "    \"power_usage\": self._get_power_usage(),\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 127, in _get_power_usage\n",
      "    return pynvml.nvmlDeviceGetPowerUsage(self.handle)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 2404, in nvmlDeviceGetPowerUsage\n",
      "    _nvmlCheckReturn(ret)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 833, in _nvmlCheckReturn\n",
      "    raise NVMLError(ret)\n",
      "pynvml.nvml.NVMLError_Unknown: Unknown Error\n",
      "[codecarbon INFO @ 21:19:17] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:19:17]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 21:19:17]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 21:19:17]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 21:19:17]   Available RAM : 31.746 GB\n",
      "[codecarbon INFO @ 21:19:17]   CPU count: 32\n",
      "[codecarbon INFO @ 21:19:17]   CPU model: 13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "[codecarbon INFO @ 21:19:17]   GPU count: 1\n",
      "[codecarbon INFO @ 21:19:17]   GPU model: 1 x NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "[codecarbon INFO @ 21:19:36] Energy consumed for RAM : 0.000051 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:19:36] Energy consumed for all GPUs : 0.000352 kWh. Total GPU Power : 82.20361724288138 W\n",
      "[codecarbon INFO @ 21:19:36] Energy consumed for all CPUs : 0.000182 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:19:36] 0.000584 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:19:51] Energy consumed for RAM : 0.000100 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:19:51] Energy consumed for all GPUs : 0.000683 kWh. Total GPU Power : 79.61734160008034 W\n",
      "[codecarbon INFO @ 21:19:51] Energy consumed for all CPUs : 0.000359 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:19:51] 0.001143 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:20:06] Energy consumed for RAM : 0.000150 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:20:06] Energy consumed for all GPUs : 0.001017 kWh. Total GPU Power : 80.04138995006615 W\n",
      "[codecarbon INFO @ 21:20:06] Energy consumed for all CPUs : 0.000536 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:20:06] 0.001703 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:20:21] Energy consumed for RAM : 0.000200 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:20:21] Energy consumed for all GPUs : 0.001351 kWh. Total GPU Power : 80.06148364721106 W\n",
      "[codecarbon INFO @ 21:20:21] Energy consumed for all CPUs : 0.000713 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:20:21] 0.002264 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:20:36] Energy consumed for RAM : 0.000249 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:20:36] Energy consumed for all GPUs : 0.001687 kWh. Total GPU Power : 80.71152652753345 W\n",
      "[codecarbon INFO @ 21:20:36] Energy consumed for all CPUs : 0.000891 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:20:36] 0.002827 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:20:51] Energy consumed for RAM : 0.000299 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:20:51] Energy consumed for all GPUs : 0.002019 kWh. Total GPU Power : 79.79850048957073 W\n",
      "[codecarbon INFO @ 21:20:51] Energy consumed for all CPUs : 0.001068 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:20:51] 0.003386 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:21:06] Energy consumed for RAM : 0.000348 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:21:06] Energy consumed for all GPUs : 0.002353 kWh. Total GPU Power : 79.94244773999154 W\n",
      "[codecarbon INFO @ 21:21:06] Energy consumed for all CPUs : 0.001245 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:21:06] 0.003946 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:21:21] Energy consumed for RAM : 0.000398 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:21:21] Energy consumed for all GPUs : 0.002685 kWh. Total GPU Power : 79.81175894391832 W\n",
      "[codecarbon INFO @ 21:21:21] Energy consumed for all CPUs : 0.001422 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:21:21] 0.004505 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-35 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\EVILAB\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 110: character maps to <undefined>\n",
      "[codecarbon INFO @ 21:21:33] Energy consumed for RAM : 0.000437 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 21:21:33] Energy consumed for all GPUs : 0.002940 kWh. Total GPU Power : 78.4362456224964 W\n",
      "[codecarbon INFO @ 21:21:33] Energy consumed for all CPUs : 0.001560 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:21:33] 0.004937 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT:                       Args                                             Values\n",
      "0              hidden_size                                                224\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                 80\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                            elu-0.5\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                224\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  retailrocket\\retailrocket_processed_view_train...\n",
      "22              valid_data  retailrocket\\retailrocket_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\retailrocket\\retailrocket_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\retailrocket\\retailrocket_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 4.868217 24.34 s 22776.01 e/s 284.70 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 4.643175 24.82 s 22338.94 e/s 279.24 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 4.591956 25.55 s 21701.40 e/s 271.27 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 4.573023 26.38 s 21014.74 e/s 262.68 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 4.563182 26.74 s 20731.29 e/s 259.14 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0016419794150644483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_tracker import track_training_C02_emissions\n",
    "\n",
    "track_training_C02_emissions(train_script_oob, \"gru4rec_pytorch_oob_bprmax\", \"retailrocket\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: python: not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(train_script_oob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_oob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test inference fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_inffix, test_script_inffix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_inffix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(train_script_inffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_inffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix, test_script_majorfix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_majorfix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(train_script_majorfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_majorfix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
