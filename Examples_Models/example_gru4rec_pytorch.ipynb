{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset, the links can be fund in the README\n",
    "dataset_path = \"../datasets/coveo_ecommerce\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Preprocess/coveo_ecommerce_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[\"coveo\"][\"params_bprmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,\"coveo_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,\"coveo_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru4rec_pytorch_script(model_name, train_folder, train_data, test_data, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, n_epochs, m, eval_hidden_reset, use_correct_loss, use_correct_mask_reset):\n",
    "    checkpoint_dir = f\"{model_path}\\\\{model_name}\"\n",
    "    s_train_full = (\n",
    "        f\"python ..\\\\GRU4REC-pytorch\\\\main.py --data_folder {train_folder} \"\n",
    "        f\"--train_data {train_data} --valid_data {test_data} --checkpoint_dir {checkpoint_dir} \"\n",
    "        f\"--num_layers 1 --embedding_dim {layers} --hidden_size {layers} \"\n",
    "        f\"--loss_type {'BPR-max' if loss == 'bpr-max' else 'CrossEntropy'} --final_act {final_act} \"\n",
    "        f\"--n_epochs {n_epochs} --batch_size {batch_size} --dropout_input {dropout_p_embed} \"\n",
    "        f\"--dropout_hidden {dropout_p_hidden} --lr {learning_rate} --momentum 0.0 \"\n",
    "        f\"--optimizer_type {'Adagrad' if optim == 'adagrad' else ''}\"\n",
    "        f\"{' --eval_hidden_reset' if eval_hidden_reset else ''}\"\n",
    "        f\"{' --use_correct_loss' if use_correct_loss else ''}\"\n",
    "        f\"{' --use_correct_mask_reset' if use_correct_mask_reset else ''}\"\n",
    "    )\n",
    "    s_test_full = s_train_full + f\" --is_eval --load_model {checkpoint_dir}\\\\model_0000{n_epochs-1}.pt --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, train_data = '/'.join(train_path.split('/')[:-1]), train_path.split('/')[-1]\n",
    "test_folder, test_data = '/'.join(test_path.split('/')[:-1]), test_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob, test_script_oob = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_oob_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=False, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../trained_models/gru4rec_pytorch_oob_bprmax\"\n",
    "eval_hidden_reset=False\n",
    "use_correct_loss=False\n",
    "use_correct_mask_reset=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Comando de entrenamiento\n",
    "process_train = subprocess.Popen(train_script_oob, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_train, stderr_train = process_train.communicate()\n",
    "\n",
    "print(\"Salida de STDOUT (Entrenamiento):\")\n",
    "print(stdout_train.decode())\n",
    "print(\"Salida de STDERR (Entrenamiento):\")\n",
    "print(stderr_train.decode())\n",
    "\n",
    "# Comando de evaluación\n",
    "process_test = subprocess.Popen(test_script_oob, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_test, stderr_test = process_test.communicate()\n",
    "\n",
    "print(\"Salida de STDOUT (Evaluación):\")\n",
    "print(stdout_test.decode())\n",
    "print(\"Salida de STDERR (Evaluación):\")\n",
    "print(stderr_test.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 18:07:42] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 18:07:42] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 18:07:42] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 18:07:43] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 18:07:43] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 18:07:43] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 18:07:46] We saw that you have a 13th Gen Intel(R) Core(TM) i9-13900HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 18:07:46] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "[codecarbon INFO @ 18:07:46] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 18:07:46]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 18:07:46]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 18:07:46]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 18:07:46]   Available RAM : 31.746 GB\n",
      "[codecarbon INFO @ 18:07:46]   CPU count: 32\n",
      "[codecarbon INFO @ 18:07:46]   CPU model: 13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "[codecarbon INFO @ 18:07:46]   GPU count: 1\n",
      "[codecarbon INFO @ 18:07:46]   GPU model: 1 x NVIDIA GeForce RTX 4090 Laptop GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: The following components were found: GPU with device(s) NVIDIA GeForce RTX 4090 Laptop GPU.\n",
      "The training of models in this work is estimated to use 0.000 kWh of electricity contributing to 0.000 kg of CO2eq. Measured by carbontracker (https://github.com/lfwa/carbontracker).\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 18:08:05] Energy consumed for RAM : 0.000050 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:08:05] Energy consumed for all GPUs : 0.000075 kWh. Total GPU Power : 18.102358800362374 W\n",
      "[codecarbon INFO @ 18:08:05] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:08:05] 0.000302 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:08:20] Energy consumed for RAM : 0.000099 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:08:20] Energy consumed for all GPUs : 0.000323 kWh. Total GPU Power : 59.311941401261564 W\n",
      "[codecarbon INFO @ 18:08:20] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:08:20] 0.000776 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:08:35] Energy consumed for RAM : 0.000149 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:08:35] Energy consumed for all GPUs : 0.000562 kWh. Total GPU Power : 57.40071912363192 W\n",
      "[codecarbon INFO @ 18:08:35] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:08:35] 0.001243 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:08:50] Energy consumed for RAM : 0.000198 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:08:50] Energy consumed for all GPUs : 0.000810 kWh. Total GPU Power : 59.508996357173466 W\n",
      "[codecarbon INFO @ 18:08:50] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:08:50] 0.001717 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:09:05] Energy consumed for RAM : 0.000248 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:09:05] Energy consumed for all GPUs : 0.001063 kWh. Total GPU Power : 60.78961886729659 W\n",
      "[codecarbon INFO @ 18:09:05] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:09:05] 0.002197 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:09:20] Energy consumed for RAM : 0.000298 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:09:20] Energy consumed for all GPUs : 0.001317 kWh. Total GPU Power : 60.904855679750405 W\n",
      "[codecarbon INFO @ 18:09:20] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:09:20] 0.002678 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:09:35] Energy consumed for RAM : 0.000347 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:09:35] Energy consumed for all GPUs : 0.001562 kWh. Total GPU Power : 58.89687832753392 W\n",
      "[codecarbon INFO @ 18:09:35] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:09:35] 0.003150 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:09:50] Energy consumed for RAM : 0.000397 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:09:50] Energy consumed for all GPUs : 0.001800 kWh. Total GPU Power : 57.117656448487864 W\n",
      "[codecarbon INFO @ 18:09:50] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:09:50] 0.003614 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:10:05] Energy consumed for RAM : 0.000446 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:10:05] Energy consumed for all GPUs : 0.002044 kWh. Total GPU Power : 58.607616522016805 W\n",
      "[codecarbon INFO @ 18:10:05] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:10:05] 0.004085 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:10:20] Energy consumed for RAM : 0.000496 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:10:20] Energy consumed for all GPUs : 0.002291 kWh. Total GPU Power : 59.21590705761753 W\n",
      "[codecarbon INFO @ 18:10:20] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:10:20] 0.004558 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:10:35] Energy consumed for RAM : 0.000545 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:10:35] Energy consumed for all GPUs : 0.002540 kWh. Total GPU Power : 59.71148614994296 W\n",
      "[codecarbon INFO @ 18:10:35] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:10:35] 0.005034 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:10:50] Energy consumed for RAM : 0.000595 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:10:50] Energy consumed for all GPUs : 0.002791 kWh. Total GPU Power : 60.22188303208718 W\n",
      "[codecarbon INFO @ 18:10:50] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:10:50] 0.005511 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:11:05] Energy consumed for RAM : 0.000644 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:11:05] Energy consumed for all GPUs : 0.003045 kWh. Total GPU Power : 60.95116560196288 W\n",
      "[codecarbon INFO @ 18:11:05] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:11:05] 0.005992 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:11:20] Energy consumed for RAM : 0.000694 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:11:20] Energy consumed for all GPUs : 0.003297 kWh. Total GPU Power : 60.44506882247016 W\n",
      "[codecarbon INFO @ 18:11:20] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:11:20] 0.006470 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 18:11:35] Energy consumed for RAM : 0.000744 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:11:35] Energy consumed for all GPUs : 0.003552 kWh. Total GPU Power : 61.169887930714935 W\n",
      "[codecarbon INFO @ 18:11:35] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:11:35] 0.006952 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-11 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\EVILAB\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\EVILAB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n",
      "[codecarbon INFO @ 18:11:44] Energy consumed for RAM : 0.000772 kWh. RAM Power : 11.904736518859863 W\n",
      "[codecarbon INFO @ 18:11:44] Energy consumed for all GPUs : 0.003689 kWh. Total GPU Power : 57.09303733038612 W\n",
      "[codecarbon INFO @ 18:11:44] Energy consumed for all CPUs : 0.002760 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 18:11:44] 0.007221 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: Average carbon intensity during training was 374.46 gCO2/kWh at detected location: Santiago, Santiago Metropolitan, CL.\n",
      "CarbonTracker: \n",
      "Actual consumption for 1 epoch(s):\n",
      "\tTime:\t0:03:54\n",
      "\tEnergy:\t0.005298935666 kWh\n",
      "\tCO2eq:\t1.984256564879 g\n",
      "\tThis is equivalent to:\n",
      "\t0.018458200604 km travelled by car\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: Live carbon intensity could not be fetched at detected location: Santiago, Santiago Metropolitan, CL. Defaulted to average carbon intensity for CL in 2021 of 374.46 gCO2/kWh. at detected location: Santiago, Santiago Metropolitan, CL.\n",
      "CarbonTracker: \n",
      "Predicted consumption for 1 epoch(s):\n",
      "\tTime:\t0:03:54\n",
      "\tEnergy:\t0.005298935666 kWh\n",
      "\tCO2eq:\t1.984256564879 g\n",
      "\tThis is equivalent to:\n",
      "\t0.018458200604 km travelled by car\n",
      "CarbonTracker: Finished monitoring.\n",
      "Salida de STDOUT:                       Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 5.545017 45.40 s 27399.16 e/s 190.27 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 5.355948 44.87 s 27726.63 e/s 192.55 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 5.288563 46.01 s 27040.25 e/s 187.78 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 5.253724 42.31 s 29399.62 e/s 204.16 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 5.233104 41.41 s 30037.89 e/s 208.60 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0024018610206306937"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_tracker import track_training_C02_emissions\n",
    "\n",
    "track_training_C02_emissions(train_script_oob, \"gru4rec_pytorch_oob_bprmax\", \"coveo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: python: not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(train_script_oob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_oob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test inference fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_inffix, test_script_inffix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_inffix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(train_script_inffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_inffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix, test_script_majorfix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_majorfix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(train_script_majorfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(test_script_majorfix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
