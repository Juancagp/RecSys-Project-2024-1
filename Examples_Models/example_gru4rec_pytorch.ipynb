{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CodeCarbon, here is your experiment id:\n",
      "8c5eece3-1309-4aea-a822-e8f636025071\n",
      "\n",
      "CodeCarbon automatically added this id to your local config: ./.codecarbon.config\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! codecarbon init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups\n",
    "import torch\n",
    "from codecarbon import EmissionsTracker\n",
    "from datetime import datetime\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from carbontracker.tracker import CarbonTracker\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_training_C02_emissions_carbontracker(command, trained_model_folder):\n",
    "    # Inicializamos el tracker\n",
    "    tracker = CarbonTracker(epochs=1)  # Usamos epochs=1 para rastrear toda la ejecución como una única época\n",
    "\n",
    "    try:\n",
    "        # Obtenemos la fecha y hora de inicio\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        # Iniciamos el tracker\n",
    "        tracker.epoch_start()\n",
    "\n",
    "        # Ejecutamos el comando de entrenamiento\n",
    "        training_process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Detenemos el tracker y obtenemos las emisiones finales\n",
    "        tracker.epoch_end()\n",
    "        tracker.stop()  # Detenemos el tracker al finalizar\n",
    "\n",
    "        # Obtenemos la fecha y hora de finalización\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        # Imprimimos la salida de la ejecución\n",
    "        print(f\"Salida de STDOUT: {training_process.stdout}\")\n",
    "\n",
    "        # Obtén las emisiones de CO2\n",
    "        emissions = tracker.final_emissions\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Ruta del archivo JSON\n",
    "    json_file_path = os.path.join(\"..\", \"trained_models\", trained_model_folder, \"trainingData.json\")\n",
    "\n",
    "    # Leer el archivo JSON existente\n",
    "    existing_data = []\n",
    "    if os.path.exists(json_file_path):\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"El archivo {json_file_path} está vacío o contiene datos inválidos, se inicializará como una lista vacía.\")\n",
    "            existing_data = []\n",
    "\n",
    "    # Preparar la información del entrenamiento\n",
    "    training_info = {\n",
    "        \"training_iteration\": len(existing_data) + 1,  # Número de iteración basado en el tamaño del dataset existente\n",
    "        \"date\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"execution_time_seconds\": (end_time - start_time).total_seconds(),\n",
    "        \"CO2_emissions_kg\": emissions\n",
    "    }\n",
    "\n",
    "    # Agregar la nueva información del entrenamiento\n",
    "    existing_data.append(training_info)\n",
    "\n",
    "    # Escribir los datos actualizados al archivo JSON\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "    # Liberar memoria\n",
    "    gc.collect()\n",
    "\n",
    "    # Finalmente, retornamos las emisiones de CO2\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar un modelo, rastrear las emisiones de CO2 y guardar la información de entrenamiento\n",
    "def track_training_C02_emissions(command, trained_model_folder, lossFunction, dataset):\n",
    "\n",
    "    # Inicializamos el tracker\n",
    "    tracker = EmissionsTracker()\n",
    "    \n",
    "    try:\n",
    "        # Obtenemos la fecha y hora de inicio\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        #iniciamos el tracker\n",
    "        tracker.start()\n",
    "        \n",
    "        # Ejecutamos el comando de entrenamiento\n",
    "        training_process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Detenemos el tracker y obtenemos las emisiones finales\n",
    "        emissions = tracker.stop()\n",
    "\n",
    "        # Obtenemos la fecha y hora de finalización\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        # Imprimimos la salida de la ejecución\n",
    "        print(f\"Salida de STDOUT: {training_process.stdout}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Ruta del archivo JSON\n",
    "    json_file_path = os.path.join(\"..\", \"trained_models\", trained_model_folder ,\"trainingData.json\")\n",
    "    \n",
    "    # Leer el archivo JSON existente\n",
    "    existing_data = []\n",
    "    if os.path.exists(json_file_path):\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"El archivo {json_file_path} está vacío o contiene datos inválidos, se inicializará como una lista vacía.\")\n",
    "            existing_data = []\n",
    "\n",
    "    # Preparar la información del entrenamiento\n",
    "    training_info = {\n",
    "        \"training_iteration\": len(existing_data) + 1,  # Número de iteración basado en el tamaño del dataset existente\n",
    "        \"date\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"execution_time_seconds\": (end_time - start_time).total_seconds(),\n",
    "        \"CO2_emissions_kg\": emissions,\n",
    "        \"LossFunction\": lossFunction,\n",
    "        \"dataset\": dataset\n",
    "\n",
    "    }\n",
    "\n",
    "    # Agregar la nueva información del entrenamiento\n",
    "    existing_data.append(training_info)\n",
    "\n",
    "    # Escribir los datos actualizados al archivo JSON\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "    # Finalmente, retornamos las emisiones de CO2\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset, the links can be fund in the README\n",
    "dataset_path = \"../datasets/diginetica\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434084 1721538 234838\n",
      "973593 261047 124195\n",
      "828902 242962 39826\n",
      "794204 208264 39793\n",
      "784957 207891 37209\n",
      "781837 204771 37209\n",
      "780685 204724 36903\n",
      "780319 204358 36903\n",
      "780139 204353 36856\n",
      "780076 204290 36856\n",
      "780044 204288 36848\n",
      "780033 204277 36848\n",
      "780031 204277 36847\n",
      "780031 204277 36847\n",
      "780031 204277 36847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:143: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:146: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:143: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:146: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:143: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:146: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Dataset  NumEvents  NumSessions  \\\n",
      "0  retail_rocket\\retailrocket_processed_view_full...     780031       204277   \n",
      "1  retail_rocket\\retailrocket_processed_view_test...      29148         8036   \n",
      "2  retail_rocket\\retailrocket_processed_view_trai...     750832       196234   \n",
      "3  retail_rocket\\retailrocket_processed_view_trai...     716989       186821   \n",
      "4  retail_rocket\\retailrocket_processed_view_trai...      33812         9408   \n",
      "\n",
      "   NumItems     NumDays                   StartTime  \\\n",
      "0     36847  137.998819  2015-05-03 03:00:40.988000   \n",
      "1     11249    6.998421  2015-09-11 03:01:15.381000   \n",
      "2     36824  130.999083  2015-05-03 03:00:40.988000   \n",
      "3     36725  123.999511  2015-05-03 03:00:40.988000   \n",
      "4     12668    6.999157  2015-09-04 03:00:34.595000   \n",
      "\n",
      "                      EndTime  AvgItemViews  MinSessionLength  \\\n",
      "0  2015-09-18 02:58:58.914000     21.169457                 2   \n",
      "1  2015-09-18 02:58:58.914000      2.591164                 2   \n",
      "2  2015-09-11 02:59:21.734000     20.389746                 2   \n",
      "3  2015-09-04 02:59:58.751000     19.523186                 2   \n",
      "4  2015-09-11 02:59:21.734000      2.669087                 2   \n",
      "\n",
      "   MaxSessionLength  AvgSessionLength  MinSessionTime (sec)  \\\n",
      "0               260          3.818496                   0.0   \n",
      "1               200          3.627178                   0.0   \n",
      "2               260          3.826207                   0.0   \n",
      "3               260          3.837839                   0.0   \n",
      "4               147          3.593963                   0.0   \n",
      "\n",
      "   MaxSessionTime (sec)  \n",
      "0             46604.003  \n",
      "1             42992.512  \n",
      "2             46604.003  \n",
      "3             46604.003  \n",
      "4             43014.633  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:143: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:146: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:143: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\retailrocket_preproc.py:146: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n"
     ]
    }
   ],
   "source": [
    "%run ../Preprocess/retailrocket_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[\"coveo\"][\"params_bprmax\"]\n",
    "params2 = setups[\"coveo\"][\"params_xe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,\"diginetica_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,\"diginetica_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru4rec_pytorch_script(model_name, train_folder, train_data, test_data, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, n_epochs, m, eval_hidden_reset, use_correct_loss, use_correct_mask_reset):\n",
    "    checkpoint_dir = f\"{model_path}\\\\{model_name}\"\n",
    "    s_train_full = (\n",
    "        f\"python ..\\\\GRU4REC-pytorch\\\\main.py --data_folder {train_folder} \"\n",
    "        f\"--train_data {train_data} --valid_data {test_data} --checkpoint_dir {checkpoint_dir} \"\n",
    "        f\"--num_layers 1 --embedding_dim {layers} --hidden_size {layers} \"\n",
    "        f\"--loss_type {'BPR-max' if loss == 'bpr-max' else 'CrossEntropy'} --final_act {final_act} \"\n",
    "        f\"--n_epochs {n_epochs} --batch_size {batch_size} --dropout_input {dropout_p_embed} \"\n",
    "        f\"--dropout_hidden {dropout_p_hidden} --lr {learning_rate} --momentum 0.0 \"\n",
    "        f\"--optimizer_type {'Adagrad' if optim == 'adagrad' else ''}\"\n",
    "        f\"{' --eval_hidden_reset' if eval_hidden_reset else ''}\"\n",
    "        f\"{' --use_correct_loss' if use_correct_loss else ''}\"\n",
    "        f\"{' --use_correct_mask_reset' if use_correct_mask_reset else ''}\"\n",
    "    )\n",
    "    s_test_full = s_train_full + f\" --is_eval --load_model {checkpoint_dir}\\\\model_0000{n_epochs-1}.pt --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la configuración de los parámetros para el entrenamiento\n",
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la configuración de los parámetros para el entrenamiento\n",
    "loss2 = params2[\"loss\"]\n",
    "optim2 = params2[\"optim\"]\n",
    "const_emb2 = params2[\"constrained_embedding\"]\n",
    "embed2 = params2[\"embedding\"]\n",
    "final_act2 = params2[\"final_act\"]\n",
    "layers2 = params2[\"layers\"]\n",
    "batch_size2 = params2[\"batch_size\"]\n",
    "dropout_p_embed2 = params2[\"dropout_p_embed\"]\n",
    "dropout_p_hidden2 = params2[\"dropout_p_hidden\"]\n",
    "learning_rate2 = params2[\"learning_rate\"]\n",
    "momentum2 = params2[\"momentum\"]\n",
    "sample_alpha2 = params2[\"sample_alpha\"]\n",
    "bpreg2 = params2[\"bpreg\"]\n",
    "logq2 = params2[\"logq\"]\n",
    "hidden_act2 = params2[\"hidden_act\"]\n",
    "n_epochs2 = 5\n",
    "m2 = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, train_data = '/'.join(train_path.split('/')[:-1]), train_path.split('/')[-1]\n",
    "test_folder, test_data = '/'.join(test_path.split('/')[:-1]), test_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob, test_script_oob = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_oob_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=False, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: The following components were found: GPU with device(s) NVIDIA GeForce RTX 4060 Laptop GPU.\n",
      "CarbonTracker: The following components were found: GPU with device(s) NVIDIA GeForce RTX 4060 Laptop GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-30 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: Average carbon intensity during training was 374.46 gCO2/kWh at detected location: Santiago, Santiago Metropolitan, CL.\n",
      "CarbonTracker: Average carbon intensity during training was 374.46 gCO2/kWh at detected location: Santiago, Santiago Metropolitan, CL.\n",
      "CarbonTracker: \n",
      "Actual consumption for 1 epoch(s):\n",
      "\tTime:\t0:04:49\n",
      "\tEnergy:\t0.006334494184 kWh\n",
      "\tCO2eq:\t2.372035152648 g\n",
      "\tThis is equivalent to:\n",
      "\t0.022065443280 km travelled by car\n",
      "CarbonTracker: \n",
      "Actual consumption for 1 epoch(s):\n",
      "\tTime:\t0:04:49\n",
      "\tEnergy:\t0.006334494184 kWh\n",
      "\tCO2eq:\t2.372035152648 g\n",
      "\tThis is equivalent to:\n",
      "\t0.022065443280 km travelled by car\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: Live carbon intensity could not be fetched at detected location: Santiago, Santiago Metropolitan, CL. Defaulted to average carbon intensity for CL in 2021 of 374.46 gCO2/kWh. at detected location: Santiago, Santiago Metropolitan, CL.\n",
      "CarbonTracker: Live carbon intensity could not be fetched at detected location: Santiago, Santiago Metropolitan, CL. Defaulted to average carbon intensity for CL in 2021 of 374.46 gCO2/kWh. at detected location: Santiago, Santiago Metropolitan, CL.\n",
      "CarbonTracker: \n",
      "Predicted consumption for 1 epoch(s):\n",
      "\tTime:\t0:04:49\n",
      "\tEnergy:\t0.006334494184 kWh\n",
      "\tCO2eq:\t2.372035152648 g\n",
      "\tThis is equivalent to:\n",
      "\t0.022065443280 km travelled by car\n",
      "CarbonTracker: \n",
      "Predicted consumption for 1 epoch(s):\n",
      "\tTime:\t0:04:49\n",
      "\tEnergy:\t0.006334494184 kWh\n",
      "\tCO2eq:\t2.372035152648 g\n",
      "\tThis is equivalent to:\n",
      "\t0.022065443280 km travelled by car\n",
      "CarbonTracker: Finished monitoring.\n",
      "CarbonTracker: Finished monitoring.\n",
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 5.545343 58.13 s 21399.55 e/s 148.61 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 5.357414 55.68 s 22340.95 e/s 155.15 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 5.289579 53.16 s 23399.24 e/s 162.49 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 5.254541 52.86 s 23535.52 e/s 163.44 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 5.233663 62.75 s 19825.83 e/s 137.68 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "\n",
      "Unexpected Error: 'CarbonTracker' object has no attribute 'final_emissions'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n",
      "CarbonTracker: WARNING - Failed to retrieve carbon intensity: Defaulting to average carbon intensity 374.46323 gCO2/kWh.\n"
     ]
    }
   ],
   "source": [
    "emissions = track_training_C02_emissions_carbontracker(train_script_oob, \"gru4rec_pytorch_oob_bprmax\")\n",
    "# Imprimimos las emisiones de carbono con estilo\n",
    "if emissions is not None:\n",
    "    display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "else:\n",
    "    display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:00:48] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 17:00:48] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:00:48] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:00:48] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:00:49] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:00:49] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 17:00:51] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 17:00:51] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 17:00:51] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:00:51]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 17:00:51]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 17:00:51]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 17:00:51]   Available RAM : 31.701 GB\n",
      "[codecarbon INFO @ 17:00:51]   CPU count: 24\n",
      "[codecarbon INFO @ 17:00:51]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 17:00:51]   GPU count: 1\n",
      "[codecarbon INFO @ 17:00:51]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 17:01:06] Energy consumed for RAM : 0.000050 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:06] Energy consumed for all GPUs : 0.000191 kWh. Total GPU Power : 45.67546141172762 W\n",
      "[codecarbon INFO @ 17:01:06] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:06] 0.000417 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:01:21] Energy consumed for RAM : 0.000099 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:21] Energy consumed for all GPUs : 0.000421 kWh. Total GPU Power : 55.32184516330861 W\n",
      "[codecarbon INFO @ 17:01:21] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:21] 0.000874 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:01:36] Energy consumed for RAM : 0.000149 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:36] Energy consumed for all GPUs : 0.000654 kWh. Total GPU Power : 55.92351958328611 W\n",
      "[codecarbon INFO @ 17:01:36] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:36] 0.001334 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:01:51] Energy consumed for RAM : 0.000198 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:51] Energy consumed for all GPUs : 0.000887 kWh. Total GPU Power : 56.029225146584395 W\n",
      "[codecarbon INFO @ 17:01:51] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:51] 0.001794 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:06] Energy consumed for RAM : 0.000248 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:06] Energy consumed for all GPUs : 0.001106 kWh. Total GPU Power : 52.525354325189646 W\n",
      "[codecarbon INFO @ 17:02:06] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:06] 0.002240 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:21] Energy consumed for RAM : 0.000297 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:21] Energy consumed for all GPUs : 0.001340 kWh. Total GPU Power : 56.19062386384083 W\n",
      "[codecarbon INFO @ 17:02:21] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:21] 0.002700 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:36] Energy consumed for RAM : 0.000347 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:36] Energy consumed for all GPUs : 0.001572 kWh. Total GPU Power : 55.69077646880421 W\n",
      "[codecarbon INFO @ 17:02:36] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:36] 0.003159 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:51] Energy consumed for RAM : 0.000396 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:51] Energy consumed for all GPUs : 0.001804 kWh. Total GPU Power : 55.662197995309604 W\n",
      "[codecarbon INFO @ 17:02:51] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:51] 0.003617 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:06] Energy consumed for RAM : 0.000446 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:06] Energy consumed for all GPUs : 0.002042 kWh. Total GPU Power : 57.119049295223476 W\n",
      "[codecarbon INFO @ 17:03:06] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:06] 0.004082 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:21] Energy consumed for RAM : 0.000495 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:21] Energy consumed for all GPUs : 0.002283 kWh. Total GPU Power : 57.64101435696136 W\n",
      "[codecarbon INFO @ 17:03:21] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:21] 0.004549 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:36] Energy consumed for RAM : 0.000545 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:36] Energy consumed for all GPUs : 0.002521 kWh. Total GPU Power : 57.16494743132621 W\n",
      "[codecarbon INFO @ 17:03:36] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:36] 0.005014 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:51] Energy consumed for RAM : 0.000594 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:51] Energy consumed for all GPUs : 0.002760 kWh. Total GPU Power : 57.4456205985992 W\n",
      "[codecarbon INFO @ 17:03:51] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:51] 0.005480 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:06] Energy consumed for RAM : 0.000644 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:06] Energy consumed for all GPUs : 0.003001 kWh. Total GPU Power : 57.833990466720316 W\n",
      "[codecarbon INFO @ 17:04:06] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:06] 0.005947 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:21] Energy consumed for RAM : 0.000693 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:21] Energy consumed for all GPUs : 0.003251 kWh. Total GPU Power : 60.062198278634554 W\n",
      "[codecarbon INFO @ 17:04:21] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:21] 0.006424 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:36] Energy consumed for RAM : 0.000743 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:36] Energy consumed for all GPUs : 0.003496 kWh. Total GPU Power : 58.68379272945868 W\n",
      "[codecarbon INFO @ 17:04:36] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:36] 0.006895 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:51] Energy consumed for RAM : 0.000792 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:51] Energy consumed for all GPUs : 0.003742 kWh. Total GPU Power : 59.18244463158085 W\n",
      "[codecarbon INFO @ 17:04:51] Energy consumed for all CPUs : 0.002834 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:51] 0.007369 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:05:06] Energy consumed for RAM : 0.000842 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:05:06] Energy consumed for all GPUs : 0.003989 kWh. Total GPU Power : 59.116372826645744 W\n",
      "[codecarbon INFO @ 17:05:06] Energy consumed for all CPUs : 0.003011 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:05:06] 0.007842 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-455 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n",
      "[codecarbon INFO @ 17:05:12] Energy consumed for RAM : 0.000862 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:05:12] Energy consumed for all GPUs : 0.004088 kWh. Total GPU Power : 58.6443996533315 W\n",
      "[codecarbon INFO @ 17:05:12] Energy consumed for all CPUs : 0.003083 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:05:12] 0.008033 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 5.545343 50.19 s 24787.27 e/s 172.13 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 5.357414 54.03 s 23026.03 e/s 159.90 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 5.289579 52.17 s 23844.61 e/s 165.59 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 5.254541 50.64 s 24566.79 e/s 170.60 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 5.233663 49.84 s 24959.70 e/s 173.33 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.0026717147524838456 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emissions = track_training_C02_emissions(train_script_oob, \"gru4rec_pytorch_oob_bprmax\")\n",
    "# Imprimimos las emisiones de carbono con estilo\n",
    "if emissions is not None:\n",
    "    display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "else:\n",
    "    display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                     [1, 5, 10, 20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                               True\n",
      "24              load_model  ../trained_models\\gru4rec_pytorch_oob_bprmax\\m...\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "Loading pre-trained model from ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "Effectivetly Loading pre-trained model from ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "Recall@1: 0.01054356 MRR@1: 0.01054356\n",
      "Recall@5: 0.03961333 MRR@5: 0.02014427\n",
      "Recall@10: 0.06833702 MRR@10: 0.02387803\n",
      "Recall@20: 0.11025748 MRR@20: 0.02673115\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Ejecutar el comando\n",
    "    result = subprocess.run(test_script_oob, shell=True, capture_output=True, text=True)\n",
    "    # Imprimir la salida estándar\n",
    "    print(result.stdout)\n",
    "\n",
    "    # Imprimir el código de retorno\n",
    "    print(result.returncode)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test inference fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_inffix, test_script_inffix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_inffix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 16:21:39] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 16:21:39] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 16:21:39] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 16:21:39] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 16:21:40] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 16:21:40] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 16:21:42] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 16:21:42] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon WARNING @ 16:21:42] Failed to retrieve gpu information\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 238, in get_gpu_details\n",
      "    devices_info.append(gpu_device.get_gpu_details())\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 75, in get_gpu_details\n",
      "    \"power_usage\": self._get_power_usage(),\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 127, in _get_power_usage\n",
      "    return pynvml.nvmlDeviceGetPowerUsage(self.handle)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 2404, in nvmlDeviceGetPowerUsage\n",
      "    _nvmlCheckReturn(ret)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 833, in _nvmlCheckReturn\n",
      "    raise NVMLError(ret)\n",
      "pynvml.nvml.NVMLError_Unknown: Unknown Error\n",
      "[codecarbon INFO @ 16:21:42] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 16:21:42]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 16:21:42]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 16:21:42]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 16:21:42]   Available RAM : 31.701 GB\n",
      "[codecarbon INFO @ 16:21:42]   CPU count: 24\n",
      "[codecarbon INFO @ 16:21:42]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 16:21:42]   GPU count: 1\n",
      "[codecarbon INFO @ 16:21:42]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 16:21:58] Energy consumed for RAM : 0.000051 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:21:58] Energy consumed for all GPUs : 0.001650 kWh. Total GPU Power : 386.189881331318 W\n",
      "[codecarbon INFO @ 16:21:58] Energy consumed for all CPUs : 0.000182 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:21:58] 0.001882 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:13] Energy consumed for RAM : 0.000100 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:13] Energy consumed for all GPUs : 0.001880 kWh. Total GPU Power : 55.27142443419566 W\n",
      "[codecarbon INFO @ 16:22:13] Energy consumed for all CPUs : 0.000359 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:13] 0.002339 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:28] Energy consumed for RAM : 0.000150 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:28] Energy consumed for all GPUs : 0.002114 kWh. Total GPU Power : 56.1574886095276 W\n",
      "[codecarbon INFO @ 16:22:28] Energy consumed for all CPUs : 0.000536 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:28] 0.002800 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:43] Energy consumed for RAM : 0.000199 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:43] Energy consumed for all GPUs : 0.002343 kWh. Total GPU Power : 54.86669887243101 W\n",
      "[codecarbon INFO @ 16:22:43] Energy consumed for all CPUs : 0.000713 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:43] 0.003255 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:58] Energy consumed for RAM : 0.000249 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:58] Energy consumed for all GPUs : 0.002577 kWh. Total GPU Power : 56.20373544530705 W\n",
      "[codecarbon INFO @ 16:22:58] Energy consumed for all CPUs : 0.000890 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:58] 0.003716 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:13] Energy consumed for RAM : 0.000298 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:13] Energy consumed for all GPUs : 0.002814 kWh. Total GPU Power : 56.87647833169374 W\n",
      "[codecarbon INFO @ 16:23:13] Energy consumed for all CPUs : 0.001067 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:13] 0.004180 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:28] Energy consumed for RAM : 0.000348 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:28] Energy consumed for all GPUs : 0.003049 kWh. Total GPU Power : 56.27481276719029 W\n",
      "[codecarbon INFO @ 16:23:28] Energy consumed for all CPUs : 0.001244 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:28] 0.004641 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:43] Energy consumed for RAM : 0.000397 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:43] Energy consumed for all GPUs : 0.003282 kWh. Total GPU Power : 56.03325877915054 W\n",
      "[codecarbon INFO @ 16:23:43] Energy consumed for all CPUs : 0.001422 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:43] 0.005101 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:58] Energy consumed for RAM : 0.000447 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:58] Energy consumed for all GPUs : 0.003519 kWh. Total GPU Power : 56.8521469587565 W\n",
      "[codecarbon INFO @ 16:23:58] Energy consumed for all CPUs : 0.001599 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:58] 0.005564 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:13] Energy consumed for RAM : 0.000496 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:13] Energy consumed for all GPUs : 0.003754 kWh. Total GPU Power : 56.45748535362943 W\n",
      "[codecarbon INFO @ 16:24:13] Energy consumed for all CPUs : 0.001776 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:13] 0.006027 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:28] Energy consumed for RAM : 0.000546 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:28] Energy consumed for all GPUs : 0.003985 kWh. Total GPU Power : 55.46855621195183 W\n",
      "[codecarbon INFO @ 16:24:28] Energy consumed for all CPUs : 0.001953 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:28] 0.006485 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:43] Energy consumed for RAM : 0.000595 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:43] Energy consumed for all GPUs : 0.004225 kWh. Total GPU Power : 57.459208873756104 W\n",
      "[codecarbon INFO @ 16:24:43] Energy consumed for all CPUs : 0.002130 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:43] 0.006950 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:58] Energy consumed for RAM : 0.000645 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:58] Energy consumed for all GPUs : 0.004469 kWh. Total GPU Power : 58.75459987438239 W\n",
      "[codecarbon INFO @ 16:24:58] Energy consumed for all CPUs : 0.002307 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:58] 0.007422 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:13] Energy consumed for RAM : 0.000694 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:13] Energy consumed for all GPUs : 0.004716 kWh. Total GPU Power : 59.01217101281182 W\n",
      "[codecarbon INFO @ 16:25:13] Energy consumed for all CPUs : 0.002484 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:13] 0.007894 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:28] Energy consumed for RAM : 0.000744 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:28] Energy consumed for all GPUs : 0.004963 kWh. Total GPU Power : 59.3370162356424 W\n",
      "[codecarbon INFO @ 16:25:28] Energy consumed for all CPUs : 0.002662 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:28] 0.008368 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:43] Energy consumed for RAM : 0.000793 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:43] Energy consumed for all GPUs : 0.005208 kWh. Total GPU Power : 58.88322690956972 W\n",
      "[codecarbon INFO @ 16:25:43] Energy consumed for all CPUs : 0.002839 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:43] 0.008840 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:58] Energy consumed for RAM : 0.000843 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:58] Energy consumed for all GPUs : 0.005454 kWh. Total GPU Power : 59.0494735089665 W\n",
      "[codecarbon INFO @ 16:25:58] Energy consumed for all CPUs : 0.003016 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:58] 0.009313 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-389 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n",
      "[codecarbon INFO @ 16:26:05] Energy consumed for RAM : 0.000866 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:26:05] Energy consumed for all GPUs : 0.005563 kWh. Total GPU Power : 56.444876945654926 W\n",
      "[codecarbon INFO @ 16:26:05] Energy consumed for all CPUs : 0.003098 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:26:05] 0.009527 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir    ../trained_models\\gru4rec_pytorch_inffix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 5.545343 50.42 s 24673.36 e/s 171.34 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 5.357414 52.25 s 23809.81 e/s 165.35 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 5.289579 52.83 s 23549.24 e/s 163.54 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 5.254541 51.44 s 24184.34 e/s 167.95 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 5.233663 49.73 s 25013.72 e/s 173.71 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.0031687758114991938 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emissions = track_training_C02_emissions(train_script_inffix, \"gru4rec_pytorch_inffix_bprmax\")\n",
    "if emissions is not None:\n",
    "    display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "else:\n",
    "    display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                     [1, 5, 10, 20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                               True\n",
      "24              load_model  ../trained_models\\gru4rec_pytorch_inffix_bprma...\n",
      "25          checkpoint_dir    ../trained_models\\gru4rec_pytorch_inffix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "Loading pre-trained model from ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00004.pt\n",
      "Effectivetly Loading pre-trained model from ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00004.pt\n",
      "Recall@1: 0.01335825 MRR@1: 0.01335825\n",
      "Recall@5: 0.05297158 MRR@5: 0.02645503\n",
      "Recall@10: 0.09099299 MRR@10: 0.03139976\n",
      "Recall@20: 0.14634090 MRR@20: 0.03519293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Ejecutar el comando\n",
    "    result = subprocess.run(test_script_inffix, shell=True, capture_output=True, text=True)\n",
    "    # Imprimir la salida estándar\n",
    "    print(result.stdout)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix_bpr, test_script_majorfix_bpr = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_majorfix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix_xl, test_script_majorfix_xl = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_majorfix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss2, optim=optim2, final_act=final_act2, layers=layers2, batch_size=batch_size2, dropout_p_embed=dropout_p_embed2, dropout_p_hidden=dropout_p_hidden2, learning_rate=learning_rate2, n_epochs=n_epochs2, m=m2, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ..\\GRU4REC-pytorch\\main.py --data_folder ../datasets --train_data diginetica\\diginetica_processed_view_train_full.tsv --valid_data diginetica\\diginetica_processed_view_test.tsv --checkpoint_dir ../trained_models\\gru4rec_pytorch_majorfix_bprmax --num_layers 1 --embedding_dim 512 --hidden_size 512 --loss_type BPR-max --final_act elu-1 --n_epochs 5 --batch_size 144 --dropout_input 0.35 --dropout_hidden 0.0 --lr 0.05 --momentum 0.0 --optimizer_type Adagrad --eval_hidden_reset --use_correct_loss --use_correct_mask_reset\n",
      "python ..\\GRU4REC-pytorch\\main.py --data_folder ../datasets --train_data diginetica\\diginetica_processed_view_train_full.tsv --valid_data diginetica\\diginetica_processed_view_test.tsv --checkpoint_dir ../trained_models\\gru4rec_pytorch_majorfix_bprmax --num_layers 1 --embedding_dim 512 --hidden_size 512 --loss_type BPR-max --final_act elu-1 --n_epochs 5 --batch_size 144 --dropout_input 0.35 --dropout_hidden 0.0 --lr 0.05 --momentum 0.0 --optimizer_type Adagrad --eval_hidden_reset --use_correct_loss --use_correct_mask_reset --is_eval --load_model ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt --m 1 5 10 20\n"
     ]
    }
   ],
   "source": [
    "print(train_script_majorfix_bpr)\n",
    "print(test_script_majorfix_bpr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 14:52:17] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 14:52:17] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 14:52:17] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 14:52:17] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 14:52:17] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 14:52:17] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 14:52:19] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 14:52:19] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 14:52:19] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 14:52:19]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 14:52:19]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 14:52:19]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 14:52:19]   Available RAM : 29.701 GB\n",
      "[codecarbon INFO @ 14:52:19]   CPU count: 24\n",
      "[codecarbon INFO @ 14:52:19]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 14:52:19]   GPU count: 1\n",
      "[codecarbon INFO @ 14:52:19]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 14:52:34] Energy consumed for RAM : 0.000046 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:52:34] Energy consumed for all GPUs : 0.000210 kWh. Total GPU Power : 50.21734194310946 W\n",
      "[codecarbon INFO @ 14:52:34] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:52:34] 0.000433 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:52:49] Energy consumed for RAM : 0.000093 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:52:49] Energy consumed for all GPUs : 0.000469 kWh. Total GPU Power : 62.19182274712937 W\n",
      "[codecarbon INFO @ 14:52:49] Energy consumed for all CPUs : 0.000355 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:52:49] 0.000916 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:53:04] Energy consumed for RAM : 0.000139 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:53:04] Energy consumed for all GPUs : 0.000734 kWh. Total GPU Power : 63.53096261708627 W\n",
      "[codecarbon INFO @ 14:53:04] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:53:04] 0.001405 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:53:19] Energy consumed for RAM : 0.000186 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:53:19] Energy consumed for all GPUs : 0.001003 kWh. Total GPU Power : 64.52502082764552 W\n",
      "[codecarbon INFO @ 14:53:19] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:53:19] 0.001897 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:53:34] Energy consumed for RAM : 0.000232 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:53:34] Energy consumed for all GPUs : 0.001276 kWh. Total GPU Power : 65.51399107221847 W\n",
      "[codecarbon INFO @ 14:53:34] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:53:34] 0.002394 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:53:49] Energy consumed for RAM : 0.000278 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:53:49] Energy consumed for all GPUs : 0.001542 kWh. Total GPU Power : 63.89425934046676 W\n",
      "[codecarbon INFO @ 14:53:49] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:53:49] 0.002884 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:54:04] Energy consumed for RAM : 0.000325 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:54:04] Energy consumed for all GPUs : 0.001815 kWh. Total GPU Power : 65.55217964529633 W\n",
      "[codecarbon INFO @ 14:54:04] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:54:04] 0.003380 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:54:19] Energy consumed for RAM : 0.000371 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:54:19] Energy consumed for all GPUs : 0.002088 kWh. Total GPU Power : 65.55141665127216 W\n",
      "[codecarbon INFO @ 14:54:19] Energy consumed for all CPUs : 0.001418 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:54:19] 0.003877 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:54:34] Energy consumed for RAM : 0.000418 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:54:34] Energy consumed for all GPUs : 0.002364 kWh. Total GPU Power : 66.08285040350042 W\n",
      "[codecarbon INFO @ 14:54:34] Energy consumed for all CPUs : 0.001595 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:54:34] 0.004376 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:54:49] Energy consumed for RAM : 0.000464 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:54:49] Energy consumed for all GPUs : 0.002640 kWh. Total GPU Power : 66.4362951643357 W\n",
      "[codecarbon INFO @ 14:54:49] Energy consumed for all CPUs : 0.001772 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:54:49] 0.004876 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:55:04] Energy consumed for RAM : 0.000510 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:55:04] Energy consumed for all GPUs : 0.002909 kWh. Total GPU Power : 64.38487754841711 W\n",
      "[codecarbon INFO @ 14:55:04] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:55:04] 0.005368 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:55:19] Energy consumed for RAM : 0.000557 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:55:19] Energy consumed for all GPUs : 0.003184 kWh. Total GPU Power : 65.98633584982969 W\n",
      "[codecarbon INFO @ 14:55:19] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:55:19] 0.005867 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:55:34] Energy consumed for RAM : 0.000603 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:55:34] Energy consumed for all GPUs : 0.003458 kWh. Total GPU Power : 65.7037047028074 W\n",
      "[codecarbon INFO @ 14:55:34] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:55:34] 0.006364 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:55:49] Energy consumed for RAM : 0.000649 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:55:49] Energy consumed for all GPUs : 0.003731 kWh. Total GPU Power : 65.53477877146865 W\n",
      "[codecarbon INFO @ 14:55:49] Energy consumed for all CPUs : 0.002481 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:55:49] 0.006861 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:56:04] Energy consumed for RAM : 0.000696 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:56:04] Energy consumed for all GPUs : 0.004004 kWh. Total GPU Power : 65.43149766641777 W\n",
      "[codecarbon INFO @ 14:56:04] Energy consumed for all CPUs : 0.002658 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:56:04] 0.007357 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:56:19] Energy consumed for RAM : 0.000742 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:56:19] Energy consumed for all GPUs : 0.004272 kWh. Total GPU Power : 64.34130053095501 W\n",
      "[codecarbon INFO @ 14:56:19] Energy consumed for all CPUs : 0.002835 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:56:19] 0.007849 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:56:34] Energy consumed for RAM : 0.000789 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:56:34] Energy consumed for all GPUs : 0.004543 kWh. Total GPU Power : 65.16434063311277 W\n",
      "[codecarbon INFO @ 14:56:34] Energy consumed for all CPUs : 0.003012 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:56:34] 0.008344 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:56:49] Energy consumed for RAM : 0.000835 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:56:49] Energy consumed for all GPUs : 0.004818 kWh. Total GPU Power : 65.91300195601409 W\n",
      "[codecarbon INFO @ 14:56:49] Energy consumed for all CPUs : 0.003189 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:56:49] 0.008842 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:57:04] Energy consumed for RAM : 0.000881 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:57:04] Energy consumed for all GPUs : 0.005088 kWh. Total GPU Power : 64.73452450031512 W\n",
      "[codecarbon INFO @ 14:57:04] Energy consumed for all CPUs : 0.003366 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:57:04] 0.009335 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:57:19] Energy consumed for RAM : 0.000928 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:57:19] Energy consumed for all GPUs : 0.005356 kWh. Total GPU Power : 64.3960463367045 W\n",
      "[codecarbon INFO @ 14:57:19] Energy consumed for all CPUs : 0.003543 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:57:19] 0.009827 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:57:34] Energy consumed for RAM : 0.000974 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:57:34] Energy consumed for all GPUs : 0.005617 kWh. Total GPU Power : 62.64404844271246 W\n",
      "[codecarbon INFO @ 14:57:34] Energy consumed for all CPUs : 0.003721 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:57:34] 0.010312 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:57:49] Energy consumed for RAM : 0.001020 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:57:49] Energy consumed for all GPUs : 0.005885 kWh. Total GPU Power : 64.27340556572135 W\n",
      "[codecarbon INFO @ 14:57:49] Energy consumed for all CPUs : 0.003898 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:57:49] 0.010803 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:58:04] Energy consumed for RAM : 0.001067 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:58:04] Energy consumed for all GPUs : 0.006151 kWh. Total GPU Power : 63.7723170696745 W\n",
      "[codecarbon INFO @ 14:58:04] Energy consumed for all CPUs : 0.004075 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:58:04] 0.011292 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:58:19] Energy consumed for RAM : 0.001113 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:58:19] Energy consumed for all GPUs : 0.006417 kWh. Total GPU Power : 63.83700604672178 W\n",
      "[codecarbon INFO @ 14:58:19] Energy consumed for all CPUs : 0.004252 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:58:19] 0.011782 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:58:34] Energy consumed for RAM : 0.001160 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:58:34] Energy consumed for all GPUs : 0.006680 kWh. Total GPU Power : 63.25343988403183 W\n",
      "[codecarbon INFO @ 14:58:34] Energy consumed for all CPUs : 0.004429 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:58:34] 0.012269 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-76 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 464: character maps to <undefined>\n",
      "[codecarbon INFO @ 14:58:37] Energy consumed for RAM : 0.001169 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 14:58:37] Energy consumed for all GPUs : 0.006726 kWh. Total GPU Power : 54.56980839964395 W\n",
      "[codecarbon INFO @ 14:58:37] Energy consumed for all CPUs : 0.004465 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:58:37] 0.012359 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                               0.35\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  diginetica\\diginetica_processed_view_train_ful...\n",
      "22              valid_data      diginetica\\diginetica_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir  ../trained_models\\gru4rec_pytorch_majorfix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                               True\n",
      "28  use_correct_mask_reset                                               True\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\diginetica\\diginetica_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 0.589589 73.87 s 8422.66 e/s 58.49 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 0.298628 73.87 s 8422.86 e/s 58.49 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 0.219527 74.05 s 8402.80 e/s 58.35 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 0.184438 75.02 s 8293.69 e/s 57.60 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 0.168235 75.71 s 8218.73 e/s 57.07 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.004110835172432228 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    emissions = track_training_C02_emissions(train_script_majorfix_bpr, \"gru4rec_pytorch_majorfix_bprmax\", \"BPR\", \"diginetica\")\n",
    "    if emissions is not None:\n",
    "        display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "    else:\n",
    "        display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                               0.35\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                     [1, 5, 10, 20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  diginetica\\diginetica_processed_view_train_ful...\n",
      "22              valid_data      diginetica\\diginetica_processed_view_test.tsv\n",
      "23                 is_eval                                               True\n",
      "24              load_model  ../trained_models\\gru4rec_pytorch_majorfix_bpr...\n",
      "25          checkpoint_dir  ../trained_models\\gru4rec_pytorch_majorfix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                               True\n",
      "28  use_correct_mask_reset                                               True\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\diginetica\\diginetica_processed_view_test.tsv\n",
      "Loading pre-trained model from ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt\n",
      "Effectivetly Loading pre-trained model from ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt\n",
      "Recall@1: 0.02828840 MRR@1: 0.02828840\n",
      "Recall@5: 0.11328976 MRR@5: 0.05658077\n",
      "Recall@10: 0.18837373 MRR@10: 0.06642809\n",
      "Recall@20: 0.28444989 MRR@20: 0.07301962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Ejecutar el comando\n",
    "    result = subprocess.run(test_script_majorfix_bpr, shell=True, capture_output=True, text=True)\n",
    "    # Imprimir la salida estándar\n",
    "    print(result.stdout)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
