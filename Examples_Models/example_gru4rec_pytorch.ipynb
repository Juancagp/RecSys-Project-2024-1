{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CodeCarbon, here is your experiment id:\n",
      "8c5eece3-1309-4aea-a822-e8f636025071\n",
      "\n",
      "CodeCarbon automatically added this id to your local config: ./.codecarbon.config\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! codecarbon init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups\n",
    "import torch\n",
    "from codecarbon import EmissionsTracker\n",
    "from datetime import datetime\n",
    "import json\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar un modelo, rastrear las emisiones de CO2 y guardar la información de entrenamiento\n",
    "def track_training_C02_emissions(command, trained_model_folder):\n",
    "\n",
    "    # Inicializamos el tracker\n",
    "    tracker = EmissionsTracker()\n",
    "    \n",
    "    try:\n",
    "        # Obtenemos la fecha y hora de inicio\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        #iniciamos el tracker\n",
    "        tracker.start()\n",
    "\n",
    "        # Ejecutamos el comando de entrenamiento\n",
    "        training_process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Detenemos el tracker y obtenemos las emisiones finales\n",
    "        emissions = tracker.stop()\n",
    "\n",
    "        # Obtenemos la fecha y hora de finalización\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        # Imprimimos la salida de la ejecución\n",
    "        print(f\"Salida de STDOUT: {training_process.stdout}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Ruta del archivo JSON\n",
    "    json_file_path = os.path.join(\"..\", \"trained_models\", trained_model_folder ,\"trainingData.json\")\n",
    "    \n",
    "    # Leer el archivo JSON existente\n",
    "    existing_data = []\n",
    "    if os.path.exists(json_file_path):\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"El archivo {json_file_path} está vacío o contiene datos inválidos, se inicializará como una lista vacía.\")\n",
    "            existing_data = []\n",
    "\n",
    "    # Preparar la información del entrenamiento\n",
    "    training_info = {\n",
    "        \"training_iteration\": len(existing_data) + 1,  # Número de iteración basado en el tamaño del dataset existente\n",
    "        \"date\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"execution_time_seconds\": (end_time - start_time).total_seconds(),\n",
    "        \"CO2_emissions_kg\": emissions\n",
    "    }\n",
    "\n",
    "    # Agregar la nueva información del entrenamiento\n",
    "    existing_data.append(training_info)\n",
    "\n",
    "    # Escribir los datos actualizados al archivo JSON\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "    # Finalmente, retornamos las emisiones de CO2\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset, the links can be fund in the README\n",
    "dataset_path = \"../datasets/coveo_ecommerce\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 12:38:54] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 12:38:54] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 12:38:54] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 12:38:54] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 12:38:54] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 12:38:54] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 12:38:56] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 12:38:56] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 12:38:56] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 12:38:56]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 12:38:56]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 12:38:56]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 12:38:56]   Available RAM : 31.701 GB\n",
      "[codecarbon INFO @ 12:38:56]   CPU count: 24\n",
      "[codecarbon INFO @ 12:38:56]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 12:38:56]   GPU count: 1\n",
      "[codecarbon INFO @ 12:38:56]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566074 274797 11365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:39:11] Energy consumed for RAM : 0.000050 kWh. RAM Power : 11.8877534866333 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464757 173480 11344\n",
      "1463706 173480 10869\n",
      "1463649 173423 10869\n",
      "1463645 173423 10868\n",
      "1463645 173423 10868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:39:12] Energy consumed for all GPUs : 0.000018 kWh. Total GPU Power : 4.1905319409242345 W\n",
      "[codecarbon INFO @ 12:39:12] Energy consumed for all CPUs : 0.000186 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 12:39:12] 0.000253 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463645 173423 10868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:177: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.min() / 1000).strftime(\n",
      "C:\\Users\\Juanc\\RecSys-Project\\RecSys-Project-2024-1\\Preprocess\\coveo_preproc.py:182: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt.datetime.utcfromtimestamp(data.Time.max() / 1000).strftime(\n",
      "[codecarbon INFO @ 12:39:18] Energy consumed for RAM : 0.000070 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 12:39:18] Energy consumed for all GPUs : 0.000033 kWh. Total GPU Power : 9.08076534645388 W\n",
      "[codecarbon INFO @ 12:39:18] Energy consumed for all CPUs : 0.000258 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 12:39:18] 0.000361 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Dataset  NumEvents  NumSessions  \\\n",
      "0      coveo_ecommerce\\coveo_processed_view_full.tsv    1463645       173423   \n",
      "1      coveo_ecommerce\\coveo_processed_view_test.tsv      52501         7748   \n",
      "2  coveo_ecommerce\\coveo_processed_view_train_ful...    1411113       165673   \n",
      "3  coveo_ecommerce\\coveo_processed_view_train_tr.tsv    1368003       159766   \n",
      "4  coveo_ecommerce\\coveo_processed_view_train_val...      43032         5905   \n",
      "\n",
      "   NumItems    NumDays                   StartTime  \\\n",
      "0     10868  17.999833  2018-12-08 00:00:11.994000   \n",
      "1      8230   0.998696  2018-12-25 00:01:50.223000   \n",
      "2     10868  16.999566  2018-12-08 00:00:11.994000   \n",
      "3     10868  15.999713  2018-12-08 00:00:11.994000   \n",
      "4      8014   0.997503  2018-12-24 00:03:10.240000   \n",
      "\n",
      "                      EndTime  AvgItemViews  MinSessionLength  \\\n",
      "0  2018-12-25 23:59:57.577000    134.674733                 2   \n",
      "1  2018-12-25 23:59:57.577000      6.379222                 2   \n",
      "2  2018-12-24 23:59:34.483000    129.841093                 2   \n",
      "3  2018-12-23 23:59:47.187000    125.874402                 2   \n",
      "4  2018-12-24 23:59:34.483000      5.369603                 2   \n",
      "\n",
      "   MaxSessionLength  AvgSessionLength  MinSessionTime (sec)  \\\n",
      "0               454          8.439740                 0.001   \n",
      "1               146          6.776071                 0.001   \n",
      "2               454          8.517459                 0.001   \n",
      "3               454          8.562541                 0.001   \n",
      "4               134          7.287384                 0.004   \n",
      "\n",
      "   MaxSessionTime (sec)  \n",
      "0             59683.003  \n",
      "1             12440.338  \n",
      "2             59683.003  \n",
      "3             59683.003  \n",
      "4             11941.152  \n",
      "Emisiones de CO2: 0.00011998682750673842 kg\n"
     ]
    }
   ],
   "source": [
    "# Definimos el tracker de emisiones\n",
    "tracker = EmissionsTracker()\n",
    "\n",
    "# Iniciamos el tracker\n",
    "tracker.start()\n",
    "\n",
    "%run ../Preprocess/coveo_preproc.py --path $dataset_path\n",
    "\n",
    "# terminado el preprocesamiento, se pausa el tracker y obtenemos el C02 emitido\n",
    "emissions = tracker.stop()\n",
    "\n",
    "# Imprimimos las emisiones\n",
    "print(f\"Emisiones de CO2: {emissions} kg\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[\"coveo\"][\"params_bprmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,\"coveo_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,\"coveo_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru4rec_pytorch_script(model_name, train_folder, train_data, test_data, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, n_epochs, m, eval_hidden_reset, use_correct_loss, use_correct_mask_reset):\n",
    "    checkpoint_dir = f\"{model_path}\\\\{model_name}\"\n",
    "    s_train_full = (\n",
    "        f\"python ..\\\\GRU4REC-pytorch\\\\main.py --data_folder {train_folder} \"\n",
    "        f\"--train_data {train_data} --valid_data {test_data} --checkpoint_dir {checkpoint_dir} \"\n",
    "        f\"--num_layers 1 --embedding_dim {layers} --hidden_size {layers} \"\n",
    "        f\"--loss_type {'BPR-max' if loss == 'bpr-max' else 'CrossEntropy'} --final_act {final_act} \"\n",
    "        f\"--n_epochs {n_epochs} --batch_size {batch_size} --dropout_input {dropout_p_embed} \"\n",
    "        f\"--dropout_hidden {dropout_p_hidden} --lr {learning_rate} --momentum 0.0 \"\n",
    "        f\"--optimizer_type {'Adagrad' if optim == 'adagrad' else ''}\"\n",
    "        f\"{' --eval_hidden_reset' if eval_hidden_reset else ''}\"\n",
    "        f\"{' --use_correct_loss' if use_correct_loss else ''}\"\n",
    "        f\"{' --use_correct_mask_reset' if use_correct_mask_reset else ''}\"\n",
    "    )\n",
    "    s_test_full = s_train_full + f\" --is_eval --load_model {checkpoint_dir}\\\\model_0000{n_epochs-1}.pt --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la configuración de los parámetros para el entrenamiento\n",
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, train_data = '/'.join(train_path.split('/')[:-1]), train_path.split('/')[-1]\n",
    "test_folder, test_data = '/'.join(test_path.split('/')[:-1]), test_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob, test_script_oob = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_oob_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=False, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:00:48] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 17:00:48] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:00:48] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:00:48] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:00:49] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:00:49] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 17:00:51] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 17:00:51] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 17:00:51] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:00:51]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 17:00:51]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 17:00:51]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 17:00:51]   Available RAM : 31.701 GB\n",
      "[codecarbon INFO @ 17:00:51]   CPU count: 24\n",
      "[codecarbon INFO @ 17:00:51]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 17:00:51]   GPU count: 1\n",
      "[codecarbon INFO @ 17:00:51]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 17:01:06] Energy consumed for RAM : 0.000050 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:06] Energy consumed for all GPUs : 0.000191 kWh. Total GPU Power : 45.67546141172762 W\n",
      "[codecarbon INFO @ 17:01:06] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:06] 0.000417 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:01:21] Energy consumed for RAM : 0.000099 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:21] Energy consumed for all GPUs : 0.000421 kWh. Total GPU Power : 55.32184516330861 W\n",
      "[codecarbon INFO @ 17:01:21] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:21] 0.000874 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:01:36] Energy consumed for RAM : 0.000149 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:36] Energy consumed for all GPUs : 0.000654 kWh. Total GPU Power : 55.92351958328611 W\n",
      "[codecarbon INFO @ 17:01:36] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:36] 0.001334 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:01:51] Energy consumed for RAM : 0.000198 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:01:51] Energy consumed for all GPUs : 0.000887 kWh. Total GPU Power : 56.029225146584395 W\n",
      "[codecarbon INFO @ 17:01:51] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:01:51] 0.001794 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:06] Energy consumed for RAM : 0.000248 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:06] Energy consumed for all GPUs : 0.001106 kWh. Total GPU Power : 52.525354325189646 W\n",
      "[codecarbon INFO @ 17:02:06] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:06] 0.002240 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:21] Energy consumed for RAM : 0.000297 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:21] Energy consumed for all GPUs : 0.001340 kWh. Total GPU Power : 56.19062386384083 W\n",
      "[codecarbon INFO @ 17:02:21] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:21] 0.002700 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:36] Energy consumed for RAM : 0.000347 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:36] Energy consumed for all GPUs : 0.001572 kWh. Total GPU Power : 55.69077646880421 W\n",
      "[codecarbon INFO @ 17:02:36] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:36] 0.003159 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:02:51] Energy consumed for RAM : 0.000396 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:02:51] Energy consumed for all GPUs : 0.001804 kWh. Total GPU Power : 55.662197995309604 W\n",
      "[codecarbon INFO @ 17:02:51] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:02:51] 0.003617 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:06] Energy consumed for RAM : 0.000446 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:06] Energy consumed for all GPUs : 0.002042 kWh. Total GPU Power : 57.119049295223476 W\n",
      "[codecarbon INFO @ 17:03:06] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:06] 0.004082 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:21] Energy consumed for RAM : 0.000495 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:21] Energy consumed for all GPUs : 0.002283 kWh. Total GPU Power : 57.64101435696136 W\n",
      "[codecarbon INFO @ 17:03:21] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:21] 0.004549 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:36] Energy consumed for RAM : 0.000545 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:36] Energy consumed for all GPUs : 0.002521 kWh. Total GPU Power : 57.16494743132621 W\n",
      "[codecarbon INFO @ 17:03:36] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:36] 0.005014 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:03:51] Energy consumed for RAM : 0.000594 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:03:51] Energy consumed for all GPUs : 0.002760 kWh. Total GPU Power : 57.4456205985992 W\n",
      "[codecarbon INFO @ 17:03:51] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:03:51] 0.005480 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:06] Energy consumed for RAM : 0.000644 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:06] Energy consumed for all GPUs : 0.003001 kWh. Total GPU Power : 57.833990466720316 W\n",
      "[codecarbon INFO @ 17:04:06] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:06] 0.005947 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:21] Energy consumed for RAM : 0.000693 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:21] Energy consumed for all GPUs : 0.003251 kWh. Total GPU Power : 60.062198278634554 W\n",
      "[codecarbon INFO @ 17:04:21] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:21] 0.006424 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:36] Energy consumed for RAM : 0.000743 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:36] Energy consumed for all GPUs : 0.003496 kWh. Total GPU Power : 58.68379272945868 W\n",
      "[codecarbon INFO @ 17:04:36] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:36] 0.006895 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:04:51] Energy consumed for RAM : 0.000792 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:04:51] Energy consumed for all GPUs : 0.003742 kWh. Total GPU Power : 59.18244463158085 W\n",
      "[codecarbon INFO @ 17:04:51] Energy consumed for all CPUs : 0.002834 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:04:51] 0.007369 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:05:06] Energy consumed for RAM : 0.000842 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:05:06] Energy consumed for all GPUs : 0.003989 kWh. Total GPU Power : 59.116372826645744 W\n",
      "[codecarbon INFO @ 17:05:06] Energy consumed for all CPUs : 0.003011 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:05:06] 0.007842 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-455 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n",
      "[codecarbon INFO @ 17:05:12] Energy consumed for RAM : 0.000862 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:05:12] Energy consumed for all GPUs : 0.004088 kWh. Total GPU Power : 58.6443996533315 W\n",
      "[codecarbon INFO @ 17:05:12] Energy consumed for all CPUs : 0.003083 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:05:12] 0.008033 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 5.545343 50.19 s 24787.27 e/s 172.13 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 5.357414 54.03 s 23026.03 e/s 159.90 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 5.289579 52.17 s 23844.61 e/s 165.59 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 5.254541 50.64 s 24566.79 e/s 170.60 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 5.233663 49.84 s 24959.70 e/s 173.33 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.0026717147524838456 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emissions = track_training_C02_emissions(train_script_oob, \"gru4rec_pytorch_oob_bprmax\")\n",
    "# Imprimimos las emisiones de carbono con estilo\n",
    "if emissions is not None:\n",
    "    display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "else:\n",
    "    display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                     [1, 5, 10, 20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                               True\n",
      "24              load_model  ../trained_models\\gru4rec_pytorch_oob_bprmax\\m...\n",
      "25          checkpoint_dir       ../trained_models\\gru4rec_pytorch_oob_bprmax\n",
      "26       eval_hidden_reset                                              False\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "Loading pre-trained model from ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "Effectivetly Loading pre-trained model from ../trained_models\\gru4rec_pytorch_oob_bprmax\\model_00004.pt\n",
      "Recall@1: 0.01054356 MRR@1: 0.01054356\n",
      "Recall@5: 0.03961333 MRR@5: 0.02014427\n",
      "Recall@10: 0.06833702 MRR@10: 0.02387803\n",
      "Recall@20: 0.11025748 MRR@20: 0.02673115\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Ejecutar el comando\n",
    "    result = subprocess.run(test_script_oob, shell=True, capture_output=True, text=True)\n",
    "    # Imprimir la salida estándar\n",
    "    print(result.stdout)\n",
    "\n",
    "    # Imprimir el código de retorno\n",
    "    print(result.returncode)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test inference fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_inffix, test_script_inffix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_inffix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=0.0, dropout_p_hidden=0.0, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=False, use_correct_mask_reset=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 16:21:39] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 16:21:39] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 16:21:39] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 16:21:39] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 16:21:40] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 16:21:40] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 16:21:42] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 16:21:42] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon WARNING @ 16:21:42] Failed to retrieve gpu information\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 238, in get_gpu_details\n",
      "    devices_info.append(gpu_device.get_gpu_details())\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 75, in get_gpu_details\n",
      "    \"power_usage\": self._get_power_usage(),\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 127, in _get_power_usage\n",
      "    return pynvml.nvmlDeviceGetPowerUsage(self.handle)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 2404, in nvmlDeviceGetPowerUsage\n",
      "    _nvmlCheckReturn(ret)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 833, in _nvmlCheckReturn\n",
      "    raise NVMLError(ret)\n",
      "pynvml.nvml.NVMLError_Unknown: Unknown Error\n",
      "[codecarbon INFO @ 16:21:42] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 16:21:42]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 16:21:42]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 16:21:42]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 16:21:42]   Available RAM : 31.701 GB\n",
      "[codecarbon INFO @ 16:21:42]   CPU count: 24\n",
      "[codecarbon INFO @ 16:21:42]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 16:21:42]   GPU count: 1\n",
      "[codecarbon INFO @ 16:21:42]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 16:21:58] Energy consumed for RAM : 0.000051 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:21:58] Energy consumed for all GPUs : 0.001650 kWh. Total GPU Power : 386.189881331318 W\n",
      "[codecarbon INFO @ 16:21:58] Energy consumed for all CPUs : 0.000182 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:21:58] 0.001882 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:13] Energy consumed for RAM : 0.000100 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:13] Energy consumed for all GPUs : 0.001880 kWh. Total GPU Power : 55.27142443419566 W\n",
      "[codecarbon INFO @ 16:22:13] Energy consumed for all CPUs : 0.000359 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:13] 0.002339 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:28] Energy consumed for RAM : 0.000150 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:28] Energy consumed for all GPUs : 0.002114 kWh. Total GPU Power : 56.1574886095276 W\n",
      "[codecarbon INFO @ 16:22:28] Energy consumed for all CPUs : 0.000536 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:28] 0.002800 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:43] Energy consumed for RAM : 0.000199 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:43] Energy consumed for all GPUs : 0.002343 kWh. Total GPU Power : 54.86669887243101 W\n",
      "[codecarbon INFO @ 16:22:43] Energy consumed for all CPUs : 0.000713 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:43] 0.003255 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:22:58] Energy consumed for RAM : 0.000249 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:22:58] Energy consumed for all GPUs : 0.002577 kWh. Total GPU Power : 56.20373544530705 W\n",
      "[codecarbon INFO @ 16:22:58] Energy consumed for all CPUs : 0.000890 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:22:58] 0.003716 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:13] Energy consumed for RAM : 0.000298 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:13] Energy consumed for all GPUs : 0.002814 kWh. Total GPU Power : 56.87647833169374 W\n",
      "[codecarbon INFO @ 16:23:13] Energy consumed for all CPUs : 0.001067 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:13] 0.004180 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:28] Energy consumed for RAM : 0.000348 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:28] Energy consumed for all GPUs : 0.003049 kWh. Total GPU Power : 56.27481276719029 W\n",
      "[codecarbon INFO @ 16:23:28] Energy consumed for all CPUs : 0.001244 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:28] 0.004641 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:43] Energy consumed for RAM : 0.000397 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:43] Energy consumed for all GPUs : 0.003282 kWh. Total GPU Power : 56.03325877915054 W\n",
      "[codecarbon INFO @ 16:23:43] Energy consumed for all CPUs : 0.001422 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:43] 0.005101 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:23:58] Energy consumed for RAM : 0.000447 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:23:58] Energy consumed for all GPUs : 0.003519 kWh. Total GPU Power : 56.8521469587565 W\n",
      "[codecarbon INFO @ 16:23:58] Energy consumed for all CPUs : 0.001599 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:23:58] 0.005564 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:13] Energy consumed for RAM : 0.000496 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:13] Energy consumed for all GPUs : 0.003754 kWh. Total GPU Power : 56.45748535362943 W\n",
      "[codecarbon INFO @ 16:24:13] Energy consumed for all CPUs : 0.001776 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:13] 0.006027 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:28] Energy consumed for RAM : 0.000546 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:28] Energy consumed for all GPUs : 0.003985 kWh. Total GPU Power : 55.46855621195183 W\n",
      "[codecarbon INFO @ 16:24:28] Energy consumed for all CPUs : 0.001953 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:28] 0.006485 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:43] Energy consumed for RAM : 0.000595 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:43] Energy consumed for all GPUs : 0.004225 kWh. Total GPU Power : 57.459208873756104 W\n",
      "[codecarbon INFO @ 16:24:43] Energy consumed for all CPUs : 0.002130 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:43] 0.006950 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:24:58] Energy consumed for RAM : 0.000645 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:24:58] Energy consumed for all GPUs : 0.004469 kWh. Total GPU Power : 58.75459987438239 W\n",
      "[codecarbon INFO @ 16:24:58] Energy consumed for all CPUs : 0.002307 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:24:58] 0.007422 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:13] Energy consumed for RAM : 0.000694 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:13] Energy consumed for all GPUs : 0.004716 kWh. Total GPU Power : 59.01217101281182 W\n",
      "[codecarbon INFO @ 16:25:13] Energy consumed for all CPUs : 0.002484 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:13] 0.007894 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:28] Energy consumed for RAM : 0.000744 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:28] Energy consumed for all GPUs : 0.004963 kWh. Total GPU Power : 59.3370162356424 W\n",
      "[codecarbon INFO @ 16:25:28] Energy consumed for all CPUs : 0.002662 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:28] 0.008368 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:43] Energy consumed for RAM : 0.000793 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:43] Energy consumed for all GPUs : 0.005208 kWh. Total GPU Power : 58.88322690956972 W\n",
      "[codecarbon INFO @ 16:25:43] Energy consumed for all CPUs : 0.002839 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:43] 0.008840 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:25:58] Energy consumed for RAM : 0.000843 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:25:58] Energy consumed for all GPUs : 0.005454 kWh. Total GPU Power : 59.0494735089665 W\n",
      "[codecarbon INFO @ 16:25:58] Energy consumed for all CPUs : 0.003016 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:25:58] 0.009313 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-389 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n",
      "[codecarbon INFO @ 16:26:05] Energy consumed for RAM : 0.000866 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 16:26:05] Energy consumed for all GPUs : 0.005563 kWh. Total GPU Power : 56.444876945654926 W\n",
      "[codecarbon INFO @ 16:26:05] Energy consumed for all CPUs : 0.003098 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 16:26:05] 0.009527 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir    ../trained_models\\gru4rec_pytorch_inffix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 5.545343 50.42 s 24673.36 e/s 171.34 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 5.357414 52.25 s 23809.81 e/s 165.35 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 5.289579 52.83 s 23549.24 e/s 163.54 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 5.254541 51.44 s 24184.34 e/s 167.95 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 5.233663 49.73 s 25013.72 e/s 173.71 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.0031687758114991938 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emissions = track_training_C02_emissions(train_script_inffix, \"gru4rec_pytorch_inffix_bprmax\")\n",
    "if emissions is not None:\n",
    "    display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "else:\n",
    "    display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box eval fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                                0.0\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                     [1, 5, 10, 20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                               True\n",
      "24              load_model  ../trained_models\\gru4rec_pytorch_inffix_bprma...\n",
      "25          checkpoint_dir    ../trained_models\\gru4rec_pytorch_inffix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                              False\n",
      "28  use_correct_mask_reset                                              False\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "Loading pre-trained model from ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00004.pt\n",
      "Effectivetly Loading pre-trained model from ../trained_models\\gru4rec_pytorch_inffix_bprmax\\model_00004.pt\n",
      "Recall@1: 0.01335825 MRR@1: 0.01335825\n",
      "Recall@5: 0.05297158 MRR@5: 0.02645503\n",
      "Recall@10: 0.09099299 MRR@10: 0.03139976\n",
      "Recall@20: 0.14634090 MRR@20: 0.03519293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Ejecutar el comando\n",
    "    result = subprocess.run(test_script_inffix, shell=True, capture_output=True, text=True)\n",
    "    # Imprimir la salida estándar\n",
    "    print(result.stdout)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_majorfix, test_script_majorfix = create_gru4rec_pytorch_script(model_name='gru4rec_pytorch_majorfix_bprmax', train_folder=train_folder, train_data=train_data, test_data=test_data, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, n_epochs=n_epochs, m=m, eval_hidden_reset=True, use_correct_loss=True, use_correct_mask_reset=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:05:53] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 17:05:53] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:05:53] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:05:53] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:05:54] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:05:54] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 17:05:56] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 17:05:56] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon WARNING @ 17:05:56] Failed to retrieve gpu information\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 238, in get_gpu_details\n",
      "    devices_info.append(gpu_device.get_gpu_details())\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 75, in get_gpu_details\n",
      "    \"power_usage\": self._get_power_usage(),\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\codecarbon\\core\\gpu.py\", line 127, in _get_power_usage\n",
      "    return pynvml.nvmlDeviceGetPowerUsage(self.handle)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 2404, in nvmlDeviceGetPowerUsage\n",
      "    _nvmlCheckReturn(ret)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pynvml\\nvml.py\", line 833, in _nvmlCheckReturn\n",
      "    raise NVMLError(ret)\n",
      "pynvml.nvml.NVMLError_Unknown: Unknown Error\n",
      "[codecarbon INFO @ 17:05:56] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:05:56]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 17:05:56]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 17:05:56]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 17:05:56]   Available RAM : 31.701 GB\n",
      "[codecarbon INFO @ 17:05:56]   CPU count: 24\n",
      "[codecarbon INFO @ 17:05:56]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 17:05:56]   GPU count: 1\n",
      "[codecarbon INFO @ 17:05:56]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 17:06:12] Energy consumed for RAM : 0.000051 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:06:12] Energy consumed for all GPUs : 0.001817 kWh. Total GPU Power : 421.9233105188734 W\n",
      "[codecarbon INFO @ 17:06:12] Energy consumed for all CPUs : 0.000183 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:06:12] 0.002052 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:06:27] Energy consumed for RAM : 0.000101 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:06:27] Energy consumed for all GPUs : 0.002001 kWh. Total GPU Power : 44.05811493076139 W\n",
      "[codecarbon INFO @ 17:06:27] Energy consumed for all CPUs : 0.000360 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:06:27] 0.002462 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:06:42] Energy consumed for RAM : 0.000150 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:06:42] Energy consumed for all GPUs : 0.002183 kWh. Total GPU Power : 43.79006447100702 W\n",
      "[codecarbon INFO @ 17:06:42] Energy consumed for all CPUs : 0.000537 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:06:42] 0.002871 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:06:57] Energy consumed for RAM : 0.000200 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:06:57] Energy consumed for all GPUs : 0.002376 kWh. Total GPU Power : 46.17256106481602 W\n",
      "[codecarbon INFO @ 17:06:57] Energy consumed for all CPUs : 0.000714 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:06:57] 0.003290 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:07:12] Energy consumed for RAM : 0.000249 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:07:12] Energy consumed for all GPUs : 0.002572 kWh. Total GPU Power : 47.039405911527126 W\n",
      "[codecarbon INFO @ 17:07:12] Energy consumed for all CPUs : 0.000892 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:07:12] 0.003713 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:07:27] Energy consumed for RAM : 0.000299 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:07:27] Energy consumed for all GPUs : 0.002762 kWh. Total GPU Power : 45.73829004601569 W\n",
      "[codecarbon INFO @ 17:07:27] Energy consumed for all CPUs : 0.001069 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:07:27] 0.004130 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:07:42] Energy consumed for RAM : 0.000348 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:07:42] Energy consumed for all GPUs : 0.002955 kWh. Total GPU Power : 46.21267034663012 W\n",
      "[codecarbon INFO @ 17:07:42] Energy consumed for all CPUs : 0.001246 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:07:42] 0.004549 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:07:57] Energy consumed for RAM : 0.000398 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:07:57] Energy consumed for all GPUs : 0.003152 kWh. Total GPU Power : 47.33876827267059 W\n",
      "[codecarbon INFO @ 17:07:57] Energy consumed for all CPUs : 0.001423 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:07:57] 0.004973 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:08:12] Energy consumed for RAM : 0.000447 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:08:12] Energy consumed for all GPUs : 0.003348 kWh. Total GPU Power : 47.05416366176 W\n",
      "[codecarbon INFO @ 17:08:12] Energy consumed for all CPUs : 0.001600 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:08:12] 0.005396 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:08:27] Energy consumed for RAM : 0.000497 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:08:27] Energy consumed for all GPUs : 0.003544 kWh. Total GPU Power : 46.94900808943463 W\n",
      "[codecarbon INFO @ 17:08:27] Energy consumed for all CPUs : 0.001777 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:08:27] 0.005818 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:08:42] Energy consumed for RAM : 0.000546 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:08:42] Energy consumed for all GPUs : 0.003738 kWh. Total GPU Power : 46.56525268375749 W\n",
      "[codecarbon INFO @ 17:08:42] Energy consumed for all CPUs : 0.001954 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:08:42] 0.006239 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:08:57] Energy consumed for RAM : 0.000596 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:08:57] Energy consumed for all GPUs : 0.003930 kWh. Total GPU Power : 46.07389670815808 W\n",
      "[codecarbon INFO @ 17:08:57] Energy consumed for all CPUs : 0.002131 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:08:57] 0.006657 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:09:12] Energy consumed for RAM : 0.000645 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:09:12] Energy consumed for all GPUs : 0.004127 kWh. Total GPU Power : 47.34449946075185 W\n",
      "[codecarbon INFO @ 17:09:12] Energy consumed for all CPUs : 0.002308 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:09:12] 0.007081 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:09:27] Energy consumed for RAM : 0.000695 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:09:27] Energy consumed for all GPUs : 0.004321 kWh. Total GPU Power : 46.57965952039314 W\n",
      "[codecarbon INFO @ 17:09:27] Energy consumed for all CPUs : 0.002486 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:09:27] 0.007502 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:09:42] Energy consumed for RAM : 0.000744 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:09:42] Energy consumed for all GPUs : 0.004516 kWh. Total GPU Power : 46.74481976250888 W\n",
      "[codecarbon INFO @ 17:09:42] Energy consumed for all CPUs : 0.002663 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:09:42] 0.007923 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:09:57] Energy consumed for RAM : 0.000794 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:09:57] Energy consumed for all GPUs : 0.004706 kWh. Total GPU Power : 45.60183561610515 W\n",
      "[codecarbon INFO @ 17:09:57] Energy consumed for all CPUs : 0.002840 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:09:57] 0.008340 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:10:12] Energy consumed for RAM : 0.000843 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:10:12] Energy consumed for all GPUs : 0.004891 kWh. Total GPU Power : 44.4489714750383 W\n",
      "[codecarbon INFO @ 17:10:12] Energy consumed for all CPUs : 0.003017 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:10:12] 0.008751 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:10:27] Energy consumed for RAM : 0.000893 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:10:27] Energy consumed for all GPUs : 0.005084 kWh. Total GPU Power : 46.285661935844516 W\n",
      "[codecarbon INFO @ 17:10:27] Energy consumed for all CPUs : 0.003194 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:10:27] 0.009171 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:10:42] Energy consumed for RAM : 0.000942 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:10:42] Energy consumed for all GPUs : 0.005283 kWh. Total GPU Power : 47.585839019902615 W\n",
      "[codecarbon INFO @ 17:10:42] Energy consumed for all CPUs : 0.003371 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:10:42] 0.009596 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:10:57] Energy consumed for RAM : 0.000992 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:10:57] Energy consumed for all GPUs : 0.005474 kWh. Total GPU Power : 45.920358165708215 W\n",
      "[codecarbon INFO @ 17:10:57] Energy consumed for all CPUs : 0.003549 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:10:57] 0.010014 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:11:12] Energy consumed for RAM : 0.001041 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:11:12] Energy consumed for all GPUs : 0.005671 kWh. Total GPU Power : 47.41222276246416 W\n",
      "[codecarbon INFO @ 17:11:12] Energy consumed for all CPUs : 0.003726 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:11:12] 0.010438 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:11:27] Energy consumed for RAM : 0.001091 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:11:27] Energy consumed for all GPUs : 0.005872 kWh. Total GPU Power : 48.077337832462995 W\n",
      "[codecarbon INFO @ 17:11:27] Energy consumed for all CPUs : 0.003903 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:11:27] 0.010865 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:11:42] Energy consumed for RAM : 0.001140 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:11:42] Energy consumed for all GPUs : 0.006071 kWh. Total GPU Power : 47.82280034616359 W\n",
      "[codecarbon INFO @ 17:11:42] Energy consumed for all CPUs : 0.004080 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:11:42] 0.011291 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:11:57] Energy consumed for RAM : 0.001190 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:11:57] Energy consumed for all GPUs : 0.006269 kWh. Total GPU Power : 47.53616200708169 W\n",
      "[codecarbon INFO @ 17:11:57] Energy consumed for all CPUs : 0.004257 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:11:57] 0.011716 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-478 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 430: character maps to <undefined>\n",
      "[codecarbon INFO @ 17:12:04] Energy consumed for RAM : 0.001210 kWh. RAM Power : 11.8877534866333 W\n",
      "[codecarbon INFO @ 17:12:04] Energy consumed for all GPUs : 0.006347 kWh. Total GPU Power : 45.7753576367631 W\n",
      "[codecarbon INFO @ 17:12:04] Energy consumed for all CPUs : 0.004329 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 17:12:04] 0.011886 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT: Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                               0.35\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                               [20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                              False\n",
      "24              load_model                                               None\n",
      "25          checkpoint_dir  ../trained_models\\gru4rec_pytorch_majorfix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                               True\n",
      "28  use_correct_mask_reset                                               True\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "#### START TRAINING....\n",
      "epoch:0 loss: 0.648210 74.51 s 16696.36 e/s 115.95 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00000.pt\n",
      "epoch:1 loss: 0.512317 71.66 s 17359.02 e/s 120.55 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00001.pt\n",
      "epoch:2 loss: 0.443904 72.48 s 17163.96 e/s 119.19 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00002.pt\n",
      "epoch:3 loss: 0.404810 73.23 s 16988.43 e/s 117.98 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00003.pt\n",
      "epoch:4 loss: 0.381162 69.04 s 18019.92 e/s 125.14 mb/s\n",
      "Save model as ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt\n",
      "\n",
      "El archivo ..\\trained_models\\gru4rec_pytorch_majorfix_bprmax\\trainingData.json está vacío o contiene datos inválidos, se inicializará como una lista vacía.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.0039534276565982305 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emissions = track_training_C02_emissions(train_script_majorfix, \"gru4rec_pytorch_majorfix_bprmax\")\n",
    "if emissions is not None:\n",
    "    display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "else:\n",
    "    display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the major fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "                      Args                                             Values\n",
      "0              hidden_size                                                512\n",
      "1               num_layers                                                  1\n",
      "2               batch_size                                                144\n",
      "3            dropout_input                                               0.35\n",
      "4           dropout_hidden                                                0.0\n",
      "5                 n_epochs                                                  5\n",
      "6                        m                                     [1, 5, 10, 20]\n",
      "7           optimizer_type                                            Adagrad\n",
      "8                final_act                                              elu-1\n",
      "9                       lr                                               0.05\n",
      "10            weight_decay                                                  0\n",
      "11                momentum                                                0.0\n",
      "12                     eps                                           0.000001\n",
      "13                    seed                                                 22\n",
      "14                   sigma                                               None\n",
      "15           embedding_dim                                                512\n",
      "16               loss_type                                            BPR-max\n",
      "17               time_sort                                              False\n",
      "18              model_name                               GRU4REC-CrossEntropy\n",
      "19                save_dir                                             models\n",
      "20             data_folder                                        ../datasets\n",
      "21              train_data  coveo_ecommerce\\coveo_processed_view_train_ful...\n",
      "22              valid_data      coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "23                 is_eval                                               True\n",
      "24              load_model  ../trained_models\\gru4rec_pytorch_majorfix_bpr...\n",
      "25          checkpoint_dir  ../trained_models\\gru4rec_pytorch_majorfix_bprmax\n",
      "26       eval_hidden_reset                                               True\n",
      "27        use_correct_loss                                               True\n",
      "28  use_correct_mask_reset                                               True\n",
      "29                    cuda                                               True\n",
      "Loading train data from ../datasets\\coveo_ecommerce\\coveo_processed_view_train_full.tsv\n",
      "Loading valid data from ../datasets\\coveo_ecommerce\\coveo_processed_view_test.tsv\n",
      "Loading pre-trained model from ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt\n",
      "Effectivetly Loading pre-trained model from ../trained_models\\gru4rec_pytorch_majorfix_bprmax\\model_00004.pt\n",
      "Recall@1: 0.01806478 MRR@1: 0.01806478\n",
      "Recall@5: 0.06030823 MRR@5: 0.03229051\n",
      "Recall@10: 0.09936785 MRR@10: 0.03743755\n",
      "Recall@20: 0.15457733 MRR@20: 0.04121002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Ejecutar el comando\n",
    "    result = subprocess.run(test_script_majorfix, shell=True, capture_output=True, text=True)\n",
    "    # Imprimir la salida estándar\n",
    "    print(result.stdout)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
