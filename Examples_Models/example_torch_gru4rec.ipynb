{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from experiment_setup import setups\n",
    "import subprocess\n",
    "import torch\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset, the links can be fund in the README\n",
    "dataset_path = \"../datasets/diginetica\"\n",
    "model_path = \"../trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar un modelo, rastrear las emisiones de CO2 y guardar la información de entrenamiento\n",
    "def track_training_C02_emissions(command, trained_model_folder, lossFunction, dataset):\n",
    "\n",
    "    # Inicializamos el tracker\n",
    "    tracker = EmissionsTracker()\n",
    "    \n",
    "    try:\n",
    "        # Obtenemos la fecha y hora de inicio\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        #iniciamos el tracker\n",
    "        tracker.start()\n",
    "        \n",
    "        # Ejecutamos el comando de entrenamiento\n",
    "        training_process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Detenemos el tracker y obtenemos las emisiones finales\n",
    "        emissions = tracker.stop()\n",
    "\n",
    "        # Obtenemos la fecha y hora de finalización\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        # Imprimimos la salida de la ejecución\n",
    "        print(f\"Salida de STDOUT: {training_process.stdout}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Ruta del archivo JSON\n",
    "    json_file_path = os.path.join(\"..\", \"trained_models\", trained_model_folder ,\"trainingData.json\")\n",
    "    \n",
    "    # Leer el archivo JSON existente\n",
    "    existing_data = []\n",
    "    if os.path.exists(json_file_path):\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"El archivo {json_file_path} está vacío o contiene datos inválidos, se inicializará como una lista vacía.\")\n",
    "            existing_data = []\n",
    "\n",
    "    # Preparar la información del entrenamiento\n",
    "    training_info = {\n",
    "        \"training_iteration\": len(existing_data) + 1,  # Número de iteración basado en el tamaño del dataset existente\n",
    "        \"date\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"execution_time_seconds\": (end_time - start_time).total_seconds(),\n",
    "        \"CO2_emissions_kg\": emissions,\n",
    "        \"LossFunction\": lossFunction,\n",
    "        \"dataset\": dataset\n",
    "\n",
    "    }\n",
    "\n",
    "    # Agregar la nueva información del entrenamiento\n",
    "    existing_data.append(training_info)\n",
    "\n",
    "    # Escribir los datos actualizados al archivo JSON\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "    # Finalmente, retornamos las emisiones de CO2\n",
    "    return emissions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocess script, specific to the dataset you chose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preprocessing script in general, executes the following steps:\n",
    "    - Loads the raw data, with correct types\n",
    "    - Creates the sessions\n",
    "    - Removes duplicated items. An item is considered as a duplicate if the preceding (based on time) event in the same session contains the exact same item.\n",
    "    - Performes iterative support filtering\n",
    "        - Removes sessions with only one event\n",
    "        - Removes items with less than 5 events\n",
    "        - Until the size of the dataset changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run coveo_preproc.py --path $dataset_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a specific setup for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = setups[\"diginetica\"][\"params_bprmax\"]\n",
    "params2 = setups[\"diginetica\"][\"params_xe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dataset_path,\"diginetica_processed_view_train_full.tsv\")\n",
    "test_path = os.path.join(dataset_path,\"diginetica_processed_view_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_gru4rec_script(model_name, train_path, test_path, model_path, loss, optim, final_act, layers, batch_size, dropout_p_embed, dropout_p_hidden, learning_rate, sample_alpha, bpreg, n_epochs, n_sample, m):\n",
    "    s_train_full = f\" python ../Torch-GRU4Rec/main.py --save_path {model_path}/{model_name} --train_path {train_path} --loss {'nll' if loss =='cross-entropy' else loss} --optimizer {optim} --n_epochs {n_epochs} --embedding_size {layers} --hidden_size {layers} --n_layers {1} --final_act {'softmaxlogit' if final_act=='softmax' else final_act} --batch_size {batch_size} --dropout_p_embed {dropout_p_embed} --dropout_p_hidden {dropout_p_hidden} --lr {learning_rate} --n_sample {n_sample} --sample_alpha {sample_alpha} --bpreg {bpreg}\"\n",
    "    s_test_full = f\" python ../Torch-GRU4Rec/main.py --train_path {train_path} --test_path {test_path} --model_path {model_path}/{model_name}/model_0000{n_epochs-1}.pt --test  --m {m}\"\n",
    "    return s_train_full, s_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = params[\"loss\"]\n",
    "optim = params[\"optim\"]\n",
    "const_emb = params[\"constrained_embedding\"]\n",
    "embed = params[\"embedding\"]\n",
    "final_act = params[\"final_act\"]\n",
    "layers = params[\"layers\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "dropout_p_embed = params[\"dropout_p_embed\"]\n",
    "dropout_p_hidden = params[\"dropout_p_hidden\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "momentum = params[\"momentum\"]\n",
    "sample_alpha = params[\"sample_alpha\"]\n",
    "bpreg = params[\"bpreg\"]\n",
    "logq = params[\"logq\"]\n",
    "hidden_act = params[\"hidden_act\"]\n",
    "n_sample = params[\"n_sample\"]\n",
    "n_epochs = 5\n",
    "m = '1 5 10 20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = params2[\"loss\"]\n",
    "optim2 = params2[\"optim\"]\n",
    "const_emb2 = params2[\"constrained_embedding\"]\n",
    "embed2 = params2[\"embedding\"]\n",
    "final_act2 = params2[\"final_act\"]\n",
    "layers2 = params2[\"layers\"]\n",
    "batch_size2 = params2[\"batch_size\"]\n",
    "dropout_p_embed2 = params2[\"dropout_p_embed\"]\n",
    "dropout_p_hidden2 = params2[\"dropout_p_hidden\"]\n",
    "learning_rate2 = params2[\"learning_rate\"]\n",
    "momentum2 = params2[\"momentum\"]\n",
    "sample_alpha2 = params2[\"sample_alpha\"]\n",
    "bpreg2 = params2[\"bpreg\"]\n",
    "logq2 = params2[\"logq\"]\n",
    "hidden_act2 = params2[\"hidden_act\"]\n",
    "n_sample2 = params2[\"n_sample\"]\n",
    "n_epochs2 = 5\n",
    "m2 = '1 5 10 20'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob_bpr, test_script_oob_bpr = create_torch_gru4rec_script(model_name='torch_gru4rec_oob_bprmax', train_path=train_path, test_path=test_path, model_path=model_path, loss=loss, optim=optim, final_act=final_act, layers=layers, batch_size=batch_size, dropout_p_embed=dropout_p_embed, dropout_p_hidden=dropout_p_hidden, learning_rate=learning_rate, sample_alpha=sample_alpha, bpreg=bpreg, n_epochs=n_epochs, n_sample=n_sample, m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_oob_xl, test_script_oob_xl = create_torch_gru4rec_script(model_name='torch_gru4rec_oob_bprmax', train_path=train_path, test_path=test_path, model_path=model_path, loss=loss2, optim=optim2, final_act=final_act2, layers=layers2, batch_size=batch_size2, dropout_p_embed=dropout_p_embed2, dropout_p_hidden=dropout_p_hidden2, learning_rate=learning_rate2, sample_alpha=sample_alpha2, bpreg=bpreg2, n_epochs=n_epochs2, n_sample=n_sample2, m=m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " python ../Torch-GRU4Rec/main.py --save_path ../trained_models/torch_gru4rec_oob_bprmax --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --loss bpr-max --optimizer adagrad --n_epochs 5 --embedding_size 512 --hidden_size 512 --n_layers 1 --final_act elu-1 --batch_size 128 --dropout_p_embed 0.5 --dropout_p_hidden 0.3 --lr 0.05 --n_sample 2048 --sample_alpha 0.3 --bpreg 0.9\n",
      " python ../Torch-GRU4Rec/main.py --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --test_path ../datasets/diginetica\\diginetica_processed_view_test.tsv --model_path ../trained_models/torch_gru4rec_oob_bprmax/model_00004.pt --test  --m 1 5 10 20\n",
      "\n",
      "\n",
      " python ../Torch-GRU4Rec/main.py --save_path ../trained_models/torch_gru4rec_oob_bprmax --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --loss nll --optimizer adagrad --n_epochs 5 --embedding_size 192 --hidden_size 192 --n_layers 1 --final_act softmaxlogit --batch_size 240 --dropout_p_embed 0.5 --dropout_p_hidden 0.05 --lr 0.085 --n_sample 2048 --sample_alpha 0.3 --bpreg 0.0\n",
      " python ../Torch-GRU4Rec/main.py --train_path ../datasets/diginetica\\diginetica_processed_view_train_full.tsv --test_path ../datasets/diginetica\\diginetica_processed_view_test.tsv --model_path ../trained_models/torch_gru4rec_oob_bprmax/model_00004.pt --test  --m 1 5 10 20\n"
     ]
    }
   ],
   "source": [
    "print(train_script_oob_bpr)\n",
    "print(test_script_oob_bpr)\n",
    "print(\"\\n\")\n",
    "print(train_script_oob_xl)\n",
    "print(test_script_oob_xl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 15:41:04] Invalid gpu_ids format. Expected a string or a list of ints.\n",
      "[codecarbon INFO @ 15:41:04] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:41:04] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:41:04] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:41:04] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 15:41:04] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 15:41:06] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700HX but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 15:41:06] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 15:41:06] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:41:06]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 15:41:06]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 15:41:06]   CodeCarbon version: 2.4.2\n",
      "[codecarbon INFO @ 15:41:06]   Available RAM : 29.701 GB\n",
      "[codecarbon INFO @ 15:41:06]   CPU count: 24\n",
      "[codecarbon INFO @ 15:41:06]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700HX\n",
      "[codecarbon INFO @ 15:41:06]   GPU count: 1\n",
      "[codecarbon INFO @ 15:41:06]   GPU model: 1 x NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[codecarbon INFO @ 15:41:21] Energy consumed for RAM : 0.000046 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:41:21] Energy consumed for all GPUs : 0.000189 kWh. Total GPU Power : 45.2016009331592 W\n",
      "[codecarbon INFO @ 15:41:21] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:41:21] 0.000412 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:41:36] Energy consumed for RAM : 0.000093 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:41:36] Energy consumed for all GPUs : 0.000450 kWh. Total GPU Power : 62.77234534792697 W\n",
      "[codecarbon INFO @ 15:41:36] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:41:36] 0.000897 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:41:51] Energy consumed for RAM : 0.000139 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:41:51] Energy consumed for all GPUs : 0.000716 kWh. Total GPU Power : 63.761484740488356 W\n",
      "[codecarbon INFO @ 15:41:51] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:41:51] 0.001387 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:42:06] Energy consumed for RAM : 0.000186 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:42:06] Energy consumed for all GPUs : 0.000985 kWh. Total GPU Power : 64.67498220133177 W\n",
      "[codecarbon INFO @ 15:42:06] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:42:06] 0.001879 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:42:21] Energy consumed for RAM : 0.000232 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:42:21] Energy consumed for all GPUs : 0.001260 kWh. Total GPU Power : 65.96150731780129 W\n",
      "[codecarbon INFO @ 15:42:21] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:42:21] 0.002378 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:42:36] Energy consumed for RAM : 0.000278 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:42:36] Energy consumed for all GPUs : 0.001522 kWh. Total GPU Power : 62.89634566488954 W\n",
      "[codecarbon INFO @ 15:42:36] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:42:36] 0.002863 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:42:51] Energy consumed for RAM : 0.000325 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:42:51] Energy consumed for all GPUs : 0.001804 kWh. Total GPU Power : 67.65360482628694 W\n",
      "[codecarbon INFO @ 15:42:51] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:42:51] 0.003369 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:43:06] Energy consumed for RAM : 0.000371 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:43:06] Energy consumed for all GPUs : 0.002087 kWh. Total GPU Power : 67.76742949316868 W\n",
      "[codecarbon INFO @ 15:43:06] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:43:06] 0.003875 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:43:21] Energy consumed for RAM : 0.000418 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:43:21] Energy consumed for all GPUs : 0.002370 kWh. Total GPU Power : 68.07777355735955 W\n",
      "[codecarbon INFO @ 15:43:21] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:43:21] 0.004382 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:43:36] Energy consumed for RAM : 0.000464 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:43:36] Energy consumed for all GPUs : 0.002635 kWh. Total GPU Power : 63.51352843834893 W\n",
      "[codecarbon INFO @ 15:43:36] Energy consumed for all CPUs : 0.001772 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:43:36] 0.004871 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:43:51] Energy consumed for RAM : 0.000510 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:43:51] Energy consumed for all GPUs : 0.002916 kWh. Total GPU Power : 67.52796162524169 W\n",
      "[codecarbon INFO @ 15:43:51] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:43:51] 0.005375 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:44:06] Energy consumed for RAM : 0.000557 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:44:06] Energy consumed for all GPUs : 0.003200 kWh. Total GPU Power : 67.98796146764248 W\n",
      "[codecarbon INFO @ 15:44:06] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:44:06] 0.005882 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:44:21] Energy consumed for RAM : 0.000603 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:44:21] Energy consumed for all GPUs : 0.003484 kWh. Total GPU Power : 68.26235013100175 W\n",
      "[codecarbon INFO @ 15:44:21] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:44:21] 0.006391 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:44:36] Energy consumed for RAM : 0.000650 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:44:36] Energy consumed for all GPUs : 0.003768 kWh. Total GPU Power : 68.1221632343785 W\n",
      "[codecarbon INFO @ 15:44:36] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:44:36] 0.006898 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:44:51] Energy consumed for RAM : 0.000696 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:44:51] Energy consumed for all GPUs : 0.004036 kWh. Total GPU Power : 64.23614162783687 W\n",
      "[codecarbon INFO @ 15:44:51] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:44:51] 0.007390 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:45:06] Energy consumed for RAM : 0.000742 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:45:06] Energy consumed for all GPUs : 0.004322 kWh. Total GPU Power : 68.63516703803222 W\n",
      "[codecarbon INFO @ 15:45:06] Energy consumed for all CPUs : 0.002835 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:45:06] 0.007899 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:45:21] Energy consumed for RAM : 0.000789 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:45:21] Energy consumed for all GPUs : 0.004605 kWh. Total GPU Power : 67.76750081917768 W\n",
      "[codecarbon INFO @ 15:45:21] Energy consumed for all CPUs : 0.003012 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:45:21] 0.008405 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:45:36] Energy consumed for RAM : 0.000835 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:45:36] Energy consumed for all GPUs : 0.004888 kWh. Total GPU Power : 67.94557136995006 W\n",
      "[codecarbon INFO @ 15:45:36] Energy consumed for all CPUs : 0.003189 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:45:36] 0.008912 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:45:51] Energy consumed for RAM : 0.000882 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:45:51] Energy consumed for all GPUs : 0.005173 kWh. Total GPU Power : 68.27245537494584 W\n",
      "[codecarbon INFO @ 15:45:51] Energy consumed for all CPUs : 0.003366 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:45:51] 0.009420 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:46:06] Energy consumed for RAM : 0.000928 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:46:06] Energy consumed for all GPUs : 0.005436 kWh. Total GPU Power : 63.26676567257957 W\n",
      "[codecarbon INFO @ 15:46:06] Energy consumed for all CPUs : 0.003543 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:46:06] 0.009908 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:46:21] Energy consumed for RAM : 0.000974 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:46:21] Energy consumed for all GPUs : 0.005717 kWh. Total GPU Power : 67.3026790744912 W\n",
      "[codecarbon INFO @ 15:46:21] Energy consumed for all CPUs : 0.003721 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:46:21] 0.010411 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:46:36] Energy consumed for RAM : 0.001021 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:46:36] Energy consumed for all GPUs : 0.005997 kWh. Total GPU Power : 67.34211286272816 W\n",
      "[codecarbon INFO @ 15:46:36] Energy consumed for all CPUs : 0.003898 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:46:36] 0.010916 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:46:51] Energy consumed for RAM : 0.001067 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:46:51] Energy consumed for all GPUs : 0.006282 kWh. Total GPU Power : 68.2856895774274 W\n",
      "[codecarbon INFO @ 15:46:51] Energy consumed for all CPUs : 0.004075 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:46:51] 0.011424 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:47:06] Energy consumed for RAM : 0.001114 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:47:06] Energy consumed for all GPUs : 0.006563 kWh. Total GPU Power : 67.42196830419498 W\n",
      "[codecarbon INFO @ 15:47:06] Energy consumed for all CPUs : 0.004252 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:47:06] 0.011929 kWh of electricity used since the beginning.\n",
      "Exception in thread Thread-37 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 486: character maps to <undefined>\n",
      "[codecarbon INFO @ 15:47:08] Energy consumed for RAM : 0.001118 kWh. RAM Power : 11.1377534866333 W\n",
      "[codecarbon INFO @ 15:47:08] Energy consumed for all GPUs : 0.006584 kWh. Total GPU Power : 46.98453501070719 W\n",
      "[codecarbon INFO @ 15:47:08] Energy consumed for all CPUs : 0.004271 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 15:47:08] 0.011974 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT:                   Args                                             Values\n",
      "0            save_path         ../trained_models/torch_gru4rec_oob_bprmax\n",
      "1           train_path  ../datasets/diginetica\\diginetica_processed_vi...\n",
      "2           valid_path                                                   \n",
      "3            test_path                                                   \n",
      "4                 test                                              False\n",
      "5                    m                                               [20]\n",
      "6           model_path                                                   \n",
      "7             n_epochs                                                  5\n",
      "8                 loss                                            bpr-max\n",
      "9            optimizer                                            adagrad\n",
      "10                  lr                                               0.05\n",
      "11      embedding_size                                                512\n",
      "12         hidden_size                                                512\n",
      "13            n_layers                                                  1\n",
      "14          batch_size                                                128\n",
      "15            n_sample                                               2048\n",
      "16      valid_n_sample                                                  0\n",
      "17     dropout_p_embed                                                0.5\n",
      "18    dropout_p_hidden                                                0.3\n",
      "19           final_act                                              elu-1\n",
      "20               bpreg                                                0.9\n",
      "21        sample_alpha                                                0.3\n",
      "22      init_as_normal                                              False\n",
      "23               sigma                                                0.0\n",
      "24         session_key                                          SessionId\n",
      "25            item_key                                             ItemId\n",
      "26            time_key                                               Time\n",
      "27                 sep                                                 \\t\n",
      "28            use_cuda                                               True\n",
      "29        weight_decay                                                0.0\n",
      "30            momentum                                                0.0\n",
      "31           time_sort                                               True\n",
      "32  train_random_order                                              False\n",
      "Loading data from ../datasets/diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Result Folder:../trained_models/torch_gru4rec_oob_bprmax\n",
      "#### START TRAINING....\n",
      "Start Epoch # 0\n",
      "epoch:0 loss: 0.581135 71.94 s 8652.80 e/s 67.72 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00000.pt\n",
      "Start Epoch # 1\n",
      "epoch:1 loss: 0.369294 70.72 s 8801.50 e/s 68.89 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00001.pt\n",
      "Start Epoch # 2\n",
      "epoch:2 loss: 0.316249 70.66 s 8809.06 e/s 68.95 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00002.pt\n",
      "Start Epoch # 3\n",
      "epoch:3 loss: 0.292057 70.85 s 8786.47 e/s 68.77 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00003.pt\n",
      "Start Epoch # 4\n",
      "epoch:4 loss: 0.277942 71.18 s 8745.35 e/s 68.45 mb/s\n",
      "Save model as ../trained_models/torch_gru4rec_oob_bprmax\\model_00004.pt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>Emisiones de CO2: 0.003982573151883324 kg</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    emissions = track_training_C02_emissions(train_script_oob_bpr, \"torch_gru4rec_oob_bprmax\", \"BPR-Max\", \"Diginetica\")\n",
    "    # Imprimimos las emisiones de carbono con estilo\n",
    "    if emissions is not None:\n",
    "        display(HTML(f\"<h2 style='color: green;'>Emisiones de CO2: {emissions} kg</h2>\"))\n",
    "    else:\n",
    "        display(HTML(\"<h2 style='color: red;'>Hubo un error durante la ejecución del comando.</h2>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the out-of-the-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-63 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 70: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de STDOUT:                   Args                                             Values\n",
      "0            save_path                                                   \n",
      "1           train_path  ../datasets/diginetica\\diginetica_processed_vi...\n",
      "2           valid_path                                                   \n",
      "3            test_path  ../datasets/diginetica\\diginetica_processed_vi...\n",
      "4                 test                                               True\n",
      "5                    m                                     [1, 5, 10, 20]\n",
      "6           model_path  ../trained_models/torch_gru4rec_oob_bprmax/mod...\n",
      "7             n_epochs                                                  5\n",
      "8                 loss                                                nll\n",
      "9            optimizer                                            adagrad\n",
      "10                  lr                                               None\n",
      "11      embedding_size                                                 -1\n",
      "12         hidden_size                                               None\n",
      "13            n_layers                                               None\n",
      "14          batch_size                                               None\n",
      "15            n_sample                                               2048\n",
      "16      valid_n_sample                                                  0\n",
      "17     dropout_p_embed                                                0.0\n",
      "18    dropout_p_hidden                                                0.0\n",
      "19           final_act                                       softmaxlogit\n",
      "20               bpreg                                                1.0\n",
      "21        sample_alpha                                                1.0\n",
      "22      init_as_normal                                              False\n",
      "23               sigma                                                0.0\n",
      "24         session_key                                          SessionId\n",
      "25            item_key                                             ItemId\n",
      "26            time_key                                               Time\n",
      "27                 sep                                                 \\t\n",
      "28            use_cuda                                               True\n",
      "29        weight_decay                                                0.0\n",
      "30            momentum                                                0.0\n",
      "31           time_sort                                               True\n",
      "32  train_random_order                                              False\n",
      "Loading data from ../datasets/diginetica\\diginetica_processed_view_train_full.tsv\n",
      "Loading data from ../datasets/diginetica\\diginetica_processed_view_test.tsv\n",
      "Test results\n",
      "recall\tmrr\t@[1, 5, 10, 20]\n",
      "Recall@1: 0.06378154 MRR@1: 0.063781545\n",
      "Recall@5: 0.20747011 MRR@5: 0.11314169\n",
      "Recall@10: 0.31479043 MRR@10: 0.12729596\n",
      "Recall@20: 0.44944078 MRR@20: 0.13652919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_process = subprocess.run(test_script_oob_bpr, shell=True, capture_output=True, text=True)\n",
    "print(f\"Salida de STDOUT: {test_process.stdout}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
